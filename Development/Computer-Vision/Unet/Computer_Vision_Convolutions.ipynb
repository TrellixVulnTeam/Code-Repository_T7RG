{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code adapted from: Lars Nieradzik's code on Object Localization https://github.com/lars76/object-localization \n",
    "#    under MIT License\n",
    "\n",
    "# Data: The Oxford-IIIT Pet Dataset http://www.robots.ox.ac.uk/~vgg/data/pets/ \n",
    "#    under Creative Commons License https://creativecommons.org/licenses/by-sa/4.0/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT LIBRARIES AND PACKAGES\n",
    "\n",
    "import csv\n",
    "import math\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.applications.mobilenet import MobileNet, preprocess_input\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import Concatenate, Conv2D, UpSampling2D, Reshape\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import binary_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETTINGS\n",
    "\n",
    "ALPHA = 1 # Width hyper parameter for MobileNet (0.25, 0.5, 0.75, 1.0). Higher width means more accurate but slower\n",
    "\n",
    "IMAGE_HEIGHT = 224\n",
    "IMAGE_WIDTH = 224\n",
    "\n",
    "HEIGHT_CELLS = 28\n",
    "WIDTH_CELLS = 28\n",
    "\n",
    "CELL_WIDTH = IMAGE_WIDTH / WIDTH_CELLS\n",
    "CELL_HEIGHT = IMAGE_HEIGHT / HEIGHT_CELLS\n",
    "\n",
    "EPOCHS = 1\n",
    "BATCH_SIZE = 4\n",
    "PATIENCE = 10\n",
    "\n",
    "THREADS = 1\n",
    "\n",
    "PATH = \"\"\n",
    "\n",
    "TRAIN_CSV = PATH+\"train.csv\"\n",
    "VALIDATION_CSV = PATH+\"validation.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(Sequence):\n",
    "\n",
    "    def __init__(self, csv_file):\n",
    "        self.paths = []\n",
    "\n",
    "        with open(csv_file, \"r\") as file:\n",
    "            self.mask = np.zeros((sum(1 for line in file), HEIGHT_CELLS, WIDTH_CELLS))\n",
    "            file.seek(0)\n",
    "\n",
    "            reader = csv.reader(file, delimiter=\",\")\n",
    "\n",
    "            for index, row in enumerate(reader):\n",
    "                for i, r in enumerate(row[1:7]):\n",
    "                    row[i+1] = int(r)\n",
    "\n",
    "                path, image_height, image_width, x0, y0, x1, y1, _, _ = row\n",
    "\n",
    "                path_mask = path.replace('.jpg','.png')\n",
    "\n",
    "                mask_img = cv2.imread(path_mask)\n",
    "                mask_img = (mask_img!=2)*1.0\n",
    "                mask_img = cv2.resize(mask_img, (28, 28))\n",
    "                mask_img = 1.0*(mask_img[:,:,0]>0.2)\n",
    "                self.mask[index,:,:] = np.squeeze(mask_img)\n",
    "                \n",
    "                self.paths.append(path)\n",
    "\n",
    "    def __len__(self):\n",
    "        return math.ceil(len(self.mask) / BATCH_SIZE)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_paths = self.paths[idx * BATCH_SIZE:(idx + 1) * BATCH_SIZE]\n",
    "        batch_masks = self.mask[idx * BATCH_SIZE:(idx + 1) * BATCH_SIZE]\n",
    "\n",
    "        batch_images = np.zeros((len(batch_paths), IMAGE_HEIGHT, IMAGE_WIDTH, 3), dtype=np.float32)\n",
    "        for i, f in enumerate(batch_paths):\n",
    "            img = Image.open(f)\n",
    "            img = img.resize((IMAGE_WIDTH, IMAGE_HEIGHT))\n",
    "            img = img.convert('RGB')\n",
    "\n",
    "            batch_images[i] = preprocess_input(np.array(img, dtype=np.float32))\n",
    "            img.close()\n",
    "\n",
    "        return batch_images, batch_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(trainable=True):\n",
    "    model = MobileNet(input_shape=(IMAGE_HEIGHT, IMAGE_WIDTH, 3), include_top=False, alpha=ALPHA, weights=\"imagenet\")\n",
    "\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = trainable\n",
    "\n",
    "    block1 = model.get_layer(\"conv_pw_5_relu\").output\n",
    "    block2 = model.get_layer(\"conv_pw_11_relu\").output\n",
    "    block3 = model.get_layer(\"conv_pw_13_relu\").output\n",
    "\n",
    "    x = Concatenate()([UpSampling2D()(block3), block2])\n",
    "    x = Concatenate()([UpSampling2D()(x), block1])\n",
    "\n",
    "    x = Conv2D(1, kernel_size=1, activation=\"sigmoid\")(x)\n",
    "    x = Reshape((HEIGHT_CELLS, WIDTH_CELLS))(x)\n",
    "\n",
    "    return Model(inputs=model.input, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coefficient(y_true, y_pred):\n",
    "    numerator = 2 * tf.reduce_sum(y_true * y_pred)\n",
    "    denominator = tf.reduce_sum(y_true + y_pred)\n",
    "\n",
    "    return numerator / (denominator + tf.keras.backend.epsilon())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) - tf.log(dice_coefficient(y_true, y_pred) + tf.keras.backend.epsilon())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-4910e5f6debd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#model.summary()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain_datagen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRAIN_CSV\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mvalidation_datagen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVALIDATION_CSV\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-57ac1072ace7>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, csv_file)\u001b[0m\n\u001b[1;32m     21\u001b[0m                 \u001b[0mmask_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmask_img\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0mmask_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m                 \u001b[0mmask_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_img\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "model = create_model(False)\n",
    "#model.summary()\n",
    "\n",
    "train_datagen = DataGenerator(TRAIN_CSV)\n",
    "validation_datagen = DataGenerator(VALIDATION_CSV)\n",
    "\n",
    "optimizer = Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "model.compile(loss=loss, optimizer=optimizer, metrics=[dice_coefficient])\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"model-{val_loss:.2f}.h5\", monitor=\"val_loss\", verbose=1, save_best_only=True,\n",
    "                             save_weights_only=True, mode=\"auto\", period=1)\n",
    "stop = EarlyStopping(monitor=\"val_loss\", patience=PATIENCE, mode=\"auto\")\n",
    "reduce_lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.2, patience=5, min_lr=1e-6, verbose=1, mode=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "751/752 [============================>.] - ETA: 2s - loss: 1.1232 - dice_coefficient: 0.6311\n",
      "Epoch 00001: val_loss improved from inf to 0.91821, saving model to model-0.92.h5\n",
      "752/752 [==============================] - 3494s 5s/step - loss: 1.1230 - dice_coefficient: 0.6312 - val_loss: 0.9182 - val_dice_coefficient: 0.6747\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a9b0cf5fd0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(generator=train_datagen,\n",
    "                    epochs=EPOCHS,\n",
    "                    validation_data=validation_datagen,\n",
    "                    callbacks=[checkpoint, reduce_lr, stop],\n",
    "                    workers=THREADS,\n",
    "                    use_multiprocessing=False,\n",
    "                    shuffle=True,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# TESTING\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from keras.applications.mobilenet import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "WEIGHTS_FILE = \"model-0.92.h5\"\n",
    "THRESHOLD = 0.8\n",
    "EPSILON = 0.02\n",
    "\n",
    "model = create_model()\n",
    "model.load_weights(WEIGHTS_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48 64 33 44\n",
      "32 48 44 55\n",
      "0 16 55 67\n",
      "0 16 67 78\n",
      "0 16 78 89\n",
      "0 16 89 100\n",
      "0 16 100 111\n",
      "0 16 111 122\n",
      "0 16 122 134\n",
      "0 16 134 145\n",
      "0 16 145 156\n",
      "0 16 156 167\n",
      "0 16 167 178\n",
      "64 80 178 190\n",
      "64 80 190 201\n",
      "64 80 201 212\n",
      "64 80 212 223\n",
      "80 96 223 234\n",
      "64 80 234 245\n",
      "144 160 245 257\n",
      "128 144 257 268\n"
     ]
    }
   ],
   "source": [
    "filename = 'images/Abyssinian_101.jpg'\n",
    "\n",
    "unscaled = cv2.imread(filename)\n",
    "image = cv2.resize(unscaled, (IMAGE_WIDTH, IMAGE_HEIGHT))\n",
    "feat_scaled = preprocess_input(np.array(image, dtype=np.float32))\n",
    "\n",
    "region = model.predict(x=np.array([feat_scaled]))[0]\n",
    "\n",
    "output = np.zeros(unscaled.shape[:2], dtype=np.uint8)\n",
    "for i in range(region.shape[1]):\n",
    "    for j in range(region.shape[0]):\n",
    "        if region[i][j] > THRESHOLD:\n",
    "            x = int(CELL_WIDTH * j * unscaled.shape[1] / IMAGE_WIDTH)\n",
    "            y = int(CELL_HEIGHT * i * unscaled.shape[0] / IMAGE_HEIGHT)\n",
    "            x2 = int(CELL_WIDTH * (j + 1) * unscaled.shape[1] / IMAGE_WIDTH)\n",
    "            y2 = int(CELL_HEIGHT * (i + 1) * unscaled.shape[0] / IMAGE_HEIGHT)\n",
    "            cv2.rectangle(unscaled, (x, y), (x2, y2), (0, 255, 0), 1)\n",
    "            print(x,x2,y,y2)\n",
    "            break\n",
    "            output[y:y2,x:x2] = 1\n",
    "\n",
    "_, contours, _ = cv2.findContours(output, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "for cnt in contours:\n",
    "    approx = cv2.approxPolyDP(cnt, EPSILON * cv2.arcLength(cnt, True), True)\n",
    "    x, y, w, h = cv2.boundingRect(approx)\n",
    "    cv2.rectangle(unscaled, (x, y), (x + w, y + h), (0, 255, 0), 1)\n",
    "\n",
    "cv2.imshow(\"image\", unscaled)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'C:/Users/Amit/Documents/Great Learning/M6 Advanced CNNs/ObjectLocalization/images/NewCats3.jpg'\n",
    "\n",
    "unscaled = cv2.imread(filename)\n",
    "image = cv2.resize(unscaled, (IMAGE_WIDTH, IMAGE_HEIGHT))\n",
    "feat_scaled = preprocess_input(np.array(image, dtype=np.float32))\n",
    "\n",
    "pred_mask = cv2.resize(1.0*(model.predict(x=np.array([feat_scaled]))[0] > 0.5), (IMAGE_WIDTH,IMAGE_HEIGHT))\n",
    "\n",
    "image2 = image\n",
    "image2[:,:,0] = pred_mask*image[:,:,0]\n",
    "image2[:,:,1] = pred_mask*image[:,:,1]\n",
    "image2[:,:,2] = pred_mask*image[:,:,2]\n",
    "\n",
    "out_image = image2\n",
    "\n",
    "cv2.imshow(\"Predicted Mask\", out_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
