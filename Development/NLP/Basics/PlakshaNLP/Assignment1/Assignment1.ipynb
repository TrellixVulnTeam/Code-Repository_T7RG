{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "Cbgl-nGTO-aF",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "38249b3ef3899e4ca804f8df5cb6c21b",
          "grade": false,
          "grade_id": "cell-e32f6782587492d5",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "# Assignment 1 : Setting up NLP Pipeline and Text Classification (10 Marks)\n",
        "\n",
        "## Due: March 7, 2022\n",
        "\n",
        "Welcome to Assignment 1 of our course on Natural Language Processing! In this assignment you will implement different text-preprocessing techniques commonly used for NLP tasks as well as implement a standard text-classification algorithm for recognizing sentiments of movie reviews.\n",
        "\n",
        "We assume that you are familiar with `python` programming language, and its libraries like `numpy` and `pandas`. We will also make use of other libraries like `nltk` and `pytorch` in the assignment. Familiarity with these libraries is not assumed so we will provide short tutorials on their usage within the assignment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFWd9il4Lu7T",
        "outputId": "0e5a6d46-e8fe-4cf4-96cf-1b592cc4cae5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/gdrive')\n",
        "    data_dir = \"/content/gdrive/MyDrive/Colab Notebooks/PlakshaNLP/Assignment1/data/SST-2\"\n",
        "except:\n",
        "    data_dir = \"/datadrive/t-kabir/work/repos/PlakshaNLP/Assignment1/data/SST-2\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "deletable": false,
        "editable": false,
        "id": "2fW_rzFZUver",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "633af3fd82c319143e02003877d9d6b1",
          "grade": false,
          "grade_id": "cell-86e7d0dd7f309c53",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "outputId": "9a7801b3-ef18-40c8-df40-b8e62be452b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.21.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.21.5)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.10.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.63.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.21.5)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (3.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (0.11.2)\n",
            "Requirement already satisfied: matplotlib>=2.2 in /usr/local/lib/python3.7/dist-packages (from seaborn) (3.2.2)\n",
            "Requirement already satisfied: pandas>=0.23 in /usr/local/lib/python3.7/dist-packages (from seaborn) (1.3.5)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.7/dist-packages (from seaborn) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from seaborn) (1.21.5)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn) (3.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn) (0.11.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23->seaborn) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=2.2->seaborn) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "# Install required libraries\n",
        "!pip install numpy\n",
        "!pip install pandas\n",
        "!pip install nltk\n",
        "!pip install torch\n",
        "!pip install tqdm\n",
        "!pip install matplotlib\n",
        "!pip install seaborn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "deletable": false,
        "editable": false,
        "id": "xYa1X_IdIeBC",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "fdb47f336d8d0f60e05da597b7e570a1",
          "grade": false,
          "grade_id": "cell-5d69275c6c01ef58",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "outputId": "8cbc0071-67f3-4f72-ff5f-3eef21ca1943"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# We start by importing libraries that we will be making use of in the assignment.\n",
        "import string\n",
        "import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import nltk\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "TN81bbKeS_7M",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "003fb04bce05fd4bf2a62392bd0aea9f",
          "grade": false,
          "grade_id": "cell-b0972535dc2a8261",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "## Stanford Sentiment Treebank Dataset\n",
        "\n",
        "For the purposes of this assignment we will be working with the [Stanford Sentiment Treebank dataset](https://nlp.stanford.edu/sentiment/treebank.html), which comprises of a list of movie reviews each tagged with the sentiment of the review. We will be considering the binary label version of the dataset commonly referred to as **SST-2**, meaning each review will have either of the two possible labels i.e. Positive or Negative.\n",
        "\n",
        "The SST-2 dataset can be downloaded from [here](https://dl.fbaipublicfiles.com/glue/data/SST-2.zip). The dataset folder will be containing three `.tsv` files, `train.tsv`, `dev.tsv` and `test.tsv` corresponding to the three splits of the data. Both `train.tsv` and `dev.tsv` have lines containing the reviews with the corresponding label (1 for positive sentiment and 0 for negative). Note that `test.tsv` only has the reviews and labels are missing, which is due to the fact that this split comes from a competition where the test predictions are to be submitted. For the purposes of this assignment we will focus on `train.tsv` and `dev.tsv` only, where the former will be used for training the text-classifiers and latter for evaluating them.\n",
        "\n",
        "We start by loading the datasets into memory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPTB0M234ZmH",
        "outputId": "dab48671-f799-4bc4-e583-da533c2af834"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Training Examples: 67349\n",
            "Number of Test Examples: 872\n"
          ]
        }
      ],
      "source": [
        "# We can use pandas to load the datasets\n",
        "train_df = pd.read_csv(f\"{data_dir}/train.tsv\", sep = \"\\t\")\n",
        "test_df = pd.read_csv(f\"{data_dir}/dev.tsv\", sep = \"\\t\")\n",
        "\n",
        "print(f\"Number of Training Examples: {len(train_df)}\")\n",
        "print(f\"Number of Test Examples: {len(test_df)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "deletable": false,
        "editable": false,
        "id": "I95nT2iAOEDB",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "636369e71f75ac9783fed9352efd9445",
          "grade": false,
          "grade_id": "cell-d2b8cefe8e3cdcdc",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "outputId": "831ef6c9-4565-4327-a1ac-94d16e8a1328"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-3e00dfca-500d-4ea2-9991-ce70390cbdd3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>hide new secretions from the parental units</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>contains no wit , only labored gags</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>that loves its characters and communicates som...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>remains utterly satisfied to remain the same t...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>on the worst revenge-of-the-nerds clichés the ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3e00dfca-500d-4ea2-9991-ce70390cbdd3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3e00dfca-500d-4ea2-9991-ce70390cbdd3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3e00dfca-500d-4ea2-9991-ce70390cbdd3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                            sentence  label\n",
              "0       hide new secretions from the parental units       0\n",
              "1               contains no wit , only labored gags       0\n",
              "2  that loves its characters and communicates som...      1\n",
              "3  remains utterly satisfied to remain the same t...      0\n",
              "4  on the worst revenge-of-the-nerds clichés the ...      0"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# View a sample of the dataset\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "4iM2Ji1xtt6e",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "d1675fb11bda4e88bc4e578a377b83e4",
          "grade": false,
          "grade_id": "cell-13023d00322e4467",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "As can be seen from the sample of training dataset using `train_df.head()`, the dataframe contains columns `sentence` and `label` containing the review and sentiment label respectively.\n",
        "\n",
        "As part of some preliminary data analysis below we visualize the distribution of the labels in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "deletable": false,
        "editable": false,
        "id": "slCgUElYOGBv",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "db057b20c1d80dedefed450b50d6cc16",
          "grade": false,
          "grade_id": "cell-05d718eb39e06ab7",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "outputId": "bf17baf9-b0bb-4b09-cffa-0c19272d27c4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 2 artists>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "label_counts = 100 * train_df[\"label\"].value_counts(normalize=True).sort_index()\n",
        "plt.bar(x = [\"Negative Sentiment\", \"Positive Sentiment\"], height = label_counts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "JoyacaXdvSVC",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "f99834d46502036de37ffa5166ce7919",
          "grade": false,
          "grade_id": "cell-00825dbebf40ad34",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "As can be seen from the plot we have roughly 45% training data points which have a negative sentiment and about 55% with positive sentiment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "SNSOIRQgvjPB",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "28c78d59a1bfe5e9b62f18ca390d39dc",
          "grade": false,
          "grade_id": "cell-9311b0cbf6236a1e",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "## Task 1: Preprocessing Pipeline for NLP (3 Marks)\n",
        "\n",
        "You will start by implementing different text-preprocessing functions below. We have provided the definitions for the functions you are supposed to implement. After filling the code for the function, you can run the cell that follows to run test cases on your code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "yO16JJysBBrL",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "adad2be3a5189c070eb2bb47e7d03ddb",
          "grade": false,
          "grade_id": "cell-51443a1b14453358",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "### Task 1.1: Word Tokenization (0.5 Marks)\n",
        "\n",
        "Before we start preprocessing the text data and eventually training classification models, it is crucial to break the text into a set of constituents called tokens which can either be sentences, words, sub-words or characters. For the purposes of this assignment we will focus on Word Tokenization i.e. breaking a piece of text into a sequence of words.\n",
        "\n",
        "There are different ways splitting a piece of text into a list of words. The simplest solution can be to split whenever a white-space character (i.e. `\" \"`) is encountered in the text i.e. if you have a string `\"this is an example of tokenization\"`, you iterate through it and whenever a white space is encountered you split the word to get: `[\"this\", \"is\", \"an\", \"example\", \"of\", \"tokenization\"]`. Implement the `whitespace_word_tokenize` function below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "id": "fLL-9xkpAvXv",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "d9ae92d4d8f4d26e1c07178726984ba7",
          "grade": false,
          "grade_id": "cell-26107c9fb9cba954",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "def whitespace_word_tokenize(text):\n",
        "  \"\"\"\n",
        "  Splits a python string containing some text to a sequence of words\n",
        "  by splitting on whitespace.\n",
        "  \n",
        "  Parameters:\n",
        "    - text (str): A Python string containing the text to be tokenized\n",
        "\n",
        "  Returns:\n",
        "    - words (list): A list contaning the words present in the text (in the same order)\n",
        "  \n",
        "  \"\"\"\n",
        "  words = None\n",
        "  words=text.split(' ')\n",
        "\n",
        "  return words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "deletable": false,
        "editable": false,
        "id": "v6AmWOL7ElWR",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "3d4cab0f183706afcc11a75f9a3ffb15",
          "grade": true,
          "grade_id": "cell-b79f7c7e45b2dbe2",
          "locked": true,
          "points": 0.25,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "outputId": "e49542e5-1869-4589-913c-9c57051c7b08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Sample Test Cases\n",
            "Sample Test Case 1:\n",
            "Input: We all live in a Yellow Submarine\n",
            "Function Output: ['We', 'all', 'live', 'in', 'a', 'Yellow', 'Submarine']\n",
            "Expected Output: ['We', 'all', 'live', 'in', 'a', 'Yellow', 'Submarine']\n",
            "Test Case Passed :)\n",
            "**********************************\n",
            "\n",
            "Sample Test Case 2:\n",
            "Input: We all live, in a Yellow Submarine.\n",
            "Function Output: ['We', 'all', 'live,', 'in', 'a', 'Yellow', 'Submarine.']\n",
            "Expected Output: ['We', 'all', 'live,', 'in', 'a', 'Yellow', 'Submarine.']\n",
            "Test Case Passed :)\n",
            "**********************************\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def evaluate_list_test_cases(test_case_input,\n",
        "                        test_case_func_output,\n",
        "                        test_case_exp_output):\n",
        "  \n",
        "  print(f\"Input: {test_case_input}\")\n",
        "  print(f\"Function Output: {test_case_func_output}\")\n",
        "  print(f\"Expected Output: {test_case_exp_output}\")\n",
        "\n",
        "  if test_case_func_output == test_case_exp_output:\n",
        "    print(\"Test Case Passed :)\")\n",
        "    print(\"**********************************\\n\")\n",
        "    return True\n",
        "  else:\n",
        "    print(\"Test Case Failed :(\")\n",
        "    print(\"**********************************\\n\")\n",
        "    return False\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "print(\"Running Sample Test Cases\")\n",
        "print(\"Sample Test Case 1:\")\n",
        "test_case = \"We all live in a Yellow Submarine\"\n",
        "test_case_answer = ['We', 'all', 'live', 'in', 'a', 'Yellow', 'Submarine']\n",
        "test_case_student_answer = whitespace_word_tokenize(test_case)\n",
        "assert evaluate_list_test_cases(test_case, test_case_student_answer, test_case_answer)\n",
        "\n",
        "print(\"Sample Test Case 2:\")\n",
        "test_case = \"We all live, in a Yellow Submarine.\"\n",
        "test_case_answer = ['We', 'all', 'live,', 'in', 'a', 'Yellow', 'Submarine.']\n",
        "test_case_student_answer = whitespace_word_tokenize(test_case)\n",
        "assert evaluate_list_test_cases(test_case, test_case_student_answer, test_case_answer)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "d8uwLxsWGKns",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "e137413a29776ecdbcf2cfae8ee396e6",
          "grade": false,
          "grade_id": "cell-246a5394ffb7af9b",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "As you can see from the outputs above the white space tokenizer does reasonably well in splitting a sentence into words. However, it is not perfect, as can be seen in the output of test case 2 this method fails to split words when punctuations are encountered which are retained as parts of the words like `\"live,\"` and `\"Submarine.\"`. \n",
        "\n",
        "One possible solution is to instead of splitting on the white-space also split when punctuations are encountered. This will partially solve the problem but there are certain other cases that still won't be handled properly by this, like we would want something like `\"don't\"` to be split into `[\"do\", \"n't\"]` instead of `[\"don\", \"'\", \"t\"]`. \n",
        "\n",
        "Thankfully, nltk package provides the `word_tokenize` function that handles most of such cases inbuilt. Implement the `nltk_word_tokenize` function below which uses `word_tokenize` function from the nltk library to tokenize the text. Refer to the documentation [here](https://www.nltk.org/api/nltk.tokenize.html#module-nltk.tokenize.treebank) to understand the usage of `word_tokenize` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "id": "EghhvTl0HXl5",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "73231f75e4bca63e47f0b56e355ec120",
          "grade": false,
          "grade_id": "cell-597ee01aabc9acf4",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "def nltk_word_tokenize(text):\n",
        "    \"\"\"\n",
        "    Splits a python string containing some text to a sequence of words\n",
        "    by using `word_tokenize` function from nltk.\n",
        "    Refer to https://www.nltk.org/api/nltk.tokenize.html#module-nltk.tokenize.treebank\n",
        "\n",
        "    Parameters:\n",
        "    - text (str): A Python string containing the text to be tokenized\n",
        "\n",
        "    Returns:\n",
        "    - words (list): A list contaning the words present in the text (in the same order)\n",
        "    \"\"\"\n",
        "    from nltk import word_tokenize\n",
        "    words = None\n",
        "\n",
        "\n",
        "    words=word_tokenize(text)\n",
        "\n",
        "    return words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "deletable": false,
        "editable": false,
        "id": "443uQMVLGJpt",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "a951f76d6d24328a3245678c814dce13",
          "grade": true,
          "grade_id": "cell-e761dcef61c6e6cb",
          "locked": true,
          "points": 0.25,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "outputId": "28e0940e-3ed0-4182-8a39-bfff5319a2c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Sample Test Cases\n",
            "Sample Test Case 1:\n",
            "Input: We all live in a Yellow Submarine\n",
            "Function Output: ['We', 'all', 'live', 'in', 'a', 'Yellow', 'Submarine']\n",
            "Expected Output: ['We', 'all', 'live', 'in', 'a', 'Yellow', 'Submarine']\n",
            "Test Case Passed :)\n",
            "**********************************\n",
            "\n",
            "Sample Test Case 2:\n",
            "Input: We all live, in a Yellow Submarine.\n",
            "Function Output: ['We', 'all', 'live', ',', 'in', 'a', 'Yellow', 'Submarine', '.']\n",
            "Expected Output: ['We', 'all', 'live', ',', 'in', 'a', 'Yellow', 'Submarine', '.']\n",
            "Test Case Passed :)\n",
            "**********************************\n",
            "\n",
            "Sample Test Case 3:\n",
            "Input: pi isn't a rational number and its approximate value is 3.14\n",
            "Function Output: ['pi', 'is', \"n't\", 'a', 'rational', 'number', 'and', 'its', 'approximate', 'value', 'is', '3.14']\n",
            "Expected Output: ['pi', 'is', \"n't\", 'a', 'rational', 'number', 'and', 'its', 'approximate', 'value', 'is', '3.14']\n",
            "Test Case Passed :)\n",
            "**********************************\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"Running Sample Test Cases\")\n",
        "print(\"Sample Test Case 1:\")\n",
        "test_case = \"We all live in a Yellow Submarine\"\n",
        "test_case_answer = ['We', 'all', 'live', 'in', 'a', 'Yellow', 'Submarine']\n",
        "test_case_student_answer = nltk_word_tokenize(test_case)\n",
        "assert evaluate_list_test_cases(test_case, test_case_student_answer, test_case_answer)\n",
        "\n",
        "print(\"Sample Test Case 2:\")\n",
        "test_case = \"We all live, in a Yellow Submarine.\"\n",
        "test_case_answer = ['We', 'all', 'live', ',', 'in', 'a', 'Yellow', 'Submarine', '.']\n",
        "test_case_student_answer = nltk_word_tokenize(test_case)\n",
        "assert evaluate_list_test_cases(test_case, test_case_student_answer, test_case_answer)\n",
        "\n",
        "print(\"Sample Test Case 3:\")\n",
        "test_case = \"pi isn't a rational number and its approximate value is 3.14\"\n",
        "test_case_answer = ['pi', 'is', \"n't\", 'a', 'rational', 'number', 'and', 'its', 'approximate', 'value', 'is', '3.14']\n",
        "test_case_student_answer = nltk_word_tokenize(test_case)\n",
        "assert evaluate_list_test_cases(test_case, test_case_student_answer, test_case_answer)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "am5naMCCLHr5",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "206d9b064e93231bc477058e88519381",
          "grade": false,
          "grade_id": "cell-e7cd8bd9cdc553ba",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "As you can see (if your test cases passed), nltk does a much better job at splitting the text into constituent words, by splitting the punctuations away from the words as well as also taking care of subtleties like splitting `\"isn't\"` into `\"is\"` and `\"n't\"` and retaining the full decimal `\"3.14\"` which would have been split into `\"3\"` and `\"14\"` if we would have naively split on punctuations along with the whitespace.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "baBb2faBwO1j",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "05be9cd48efdb108be958cd8294c773a",
          "grade": false,
          "grade_id": "cell-875623b28d021978",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "### Task 1.2: Convert the text to lower case (0.25 Marks)\n",
        "\n",
        "We start the with the most basic of all text preprocessing techniques i.e. converting all the words in the text into lower case. As you will see soon, NLP models often treat different words as different entities and by default do not assume any relation between them. For eg. A word `Bat` will be treated differently from the word `bat` if we use them seperately to define the features. Hence it can be useful to remove such artifacts from the datasets so that we can have common representations for the same words.\n",
        "\n",
        "Complete the function definiton below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "id": "H6vUkukMwLDI",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "1845d4fe75f9975c85ba069e3da1f95a",
          "grade": false,
          "grade_id": "cell-3e47327b34745799",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "def to_lower_case(text):\n",
        "  \"\"\" Converts a piece of text to only contain words in lower case\n",
        "  \n",
        "  Parameters:\n",
        "    - text (str): A Python string containing the text to be lower-cased\n",
        "\n",
        "  Returns:\n",
        "    - text_lower_case (str): A string containing the input text in lower case\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  text_lower_case = None\n",
        "\n",
        "  text_lower_case=text.lower()\n",
        "  return text_lower_case"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "deletable": false,
        "editable": false,
        "id": "rumqsZp2vPwL",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "bb3ef2c9b4e70abe28383b056fa15685",
          "grade": true,
          "grade_id": "cell-c3f69a62a997c91e",
          "locked": true,
          "points": 0.25,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "outputId": "3c13ffc9-95a2-4b15-f2e2-d77b5db4b00f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Sample Test Cases\n",
            "Sample Test Case 1:\n",
            "Input: We all live in a Yellow Submarine\n",
            "Function Output: we all live in a yellow submarine\n",
            "Expected Output: we all live in a yellow submarine\n",
            "Test Case Passed :)\n",
            "**********************************\n",
            "\n",
            "Sample Test Case 2:\n",
            "Input: SuRRender To The Void, iT is SHINNING\n",
            "Function Output: surrender to the void, it is shinning\n",
            "Expected Output: surrender to the void, it is shinning\n",
            "Test Case Passed :)\n",
            "**********************************\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\"\"\"Don't change code in this cell\"\"\"\n",
        "#SAMPLE TEST CASE\n",
        "\n",
        "def evaluate_string_test_cases(test_case_input,\n",
        "                        test_case_func_output,\n",
        "                        test_case_exp_output):\n",
        "  \n",
        "  print(f\"Input: {test_case_input}\")\n",
        "  print(f\"Function Output: {test_case_func_output}\")\n",
        "  print(f\"Expected Output: {test_case_exp_output}\")\n",
        "\n",
        "  if test_case_func_output == test_case_exp_output:\n",
        "    print(\"Test Case Passed :)\")\n",
        "    print(\"**********************************\\n\")\n",
        "    return True\n",
        "  else:\n",
        "    print(\"Test Case Failed :(\")\n",
        "    print(\"**********************************\\n\")\n",
        "    return False\n",
        "\n",
        "\n",
        "print(\"Running Sample Test Cases\")\n",
        "print(\"Sample Test Case 1:\")\n",
        "test_case = \"We all live in a Yellow Submarine\"\n",
        "test_case_answer = \"we all live in a yellow submarine\"\n",
        "test_case_student_answer = to_lower_case(test_case)\n",
        "assert evaluate_string_test_cases(test_case, test_case_student_answer, test_case_answer)\n",
        "\n",
        "print(\"Sample Test Case 2:\")\n",
        "test_case = \"SuRRender To The Void, iT is SHINNING\"\n",
        "test_case_answer = \"surrender to the void, it is shinning\"\n",
        "test_case_student_answer = to_lower_case(test_case)\n",
        "assert evaluate_string_test_cases(test_case, test_case_student_answer, test_case_answer)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "MfgtHs-sVjJs",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "0fda9e5ccf09091b214f3c136a1565ae",
          "grade": false,
          "grade_id": "cell-8f84dbf3659373ba",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "### Task 1.3: Remove Punctuations (0.5 Marks)\n",
        "\n",
        "Another common way to reduce the number of word variations in the text like `hello` vs `hello,` is to remove punctuations. While for some NLP tasks like POS tagging punctuations might be helpful, for classification tasks punctuations can be assumed to have negligible effect on the actual label.\n",
        "\n",
        "Complete the function `remove_punctuations` below. Examples for the function's working are:\n",
        "\n",
        "| Input                                                                                                  | Expected Output                                                                                  |\n",
        "|--------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------|\n",
        "| Mr. and Mrs. Dursley, of number four, Privet Drive, were proud to say that they were perfectly normal! | Mr and Mrs Dursley of number four Privet Drive were proud to say that they were perfectly normal |\n",
        "| \"Little tyke,\" chortled Mr. Dursley as he left the house.                                              | Little tyke chortled Mr Dursley as he left the house                                             |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "id": "PdBqyCoWan9S",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "fd3b994293d508480a95d9aba75b21ad",
          "grade": false,
          "grade_id": "cell-d189c80b31a5ca50",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "def remove_punctuations(text):\n",
        "    \"\"\" \n",
        "    Removes punctuations from a piece of text.\n",
        "\n",
        "    Parameters:\n",
        "    - text (str) : A Python string containing text from which punctuation is to be removed\n",
        "\n",
        "    Returns:\n",
        "    - text_no_punct (str): Resulting string after removing punctuation.\n",
        "\n",
        "    Hint: You can use `string.punctuation` to get a string containing all punctuation symbols.\n",
        "    >>> print(string.punctuation)\n",
        "    '!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    text_no_punct = None\n",
        "\n",
        "    punctuations=string.punctuation\n",
        "    text_no_punct=text.translate(str.maketrans('','',string.punctuation))\n",
        "    return text_no_punct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "deletable": false,
        "editable": false,
        "id": "XnjHFPs3b8fE",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "d79f662f18c2736569f32aea54469179",
          "grade": true,
          "grade_id": "cell-bc45beb88678c7c0",
          "locked": true,
          "points": 0.5,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "outputId": "21e3aaca-6bcb-48b6-8a24-7a81ff70443a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Sample Test Cases\n",
            "Sample Test Case 1:\n",
            "Input: Mr. and Mrs. Dursley, of number four, Privet Drive, were proud to say that they were perfectly normal!\n",
            "Function Output: Mr and Mrs Dursley of number four Privet Drive were proud to say that they were perfectly normal\n",
            "Expected Output: Mr and Mrs Dursley of number four Privet Drive were proud to say that they were perfectly normal\n",
            "Test Case Passed :)\n",
            "**********************************\n",
            "\n",
            "Sample Test Case 2:\n",
            "Input: \"Little tyke,\" chortled Mr. Dursley as he left the house.\n",
            "Function Output: Little tyke chortled Mr Dursley as he left the house\n",
            "Expected Output: Little tyke chortled Mr Dursley as he left the house\n",
            "Test Case Passed :)\n",
            "**********************************\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"Running Sample Test Cases\")\n",
        "print(\"Sample Test Case 1:\")\n",
        "test_case = \"Mr. and Mrs. Dursley, of number four, Privet Drive, were proud to say that they were perfectly normal!\"\n",
        "test_case_answer = \"Mr and Mrs Dursley of number four Privet Drive were proud to say that they were perfectly normal\"\n",
        "test_case_student_answer = remove_punctuations(test_case)\n",
        "assert evaluate_string_test_cases(test_case, test_case_student_answer, test_case_answer)\n",
        "\n",
        "print(\"Sample Test Case 2:\")\n",
        "test_case = \"\\\"Little tyke,\\\" chortled Mr. Dursley as he left the house.\"\n",
        "test_case_answer = \"Little tyke chortled Mr Dursley as he left the house\"\n",
        "test_case_student_answer = remove_punctuations(test_case)\n",
        "assert evaluate_string_test_cases(test_case, test_case_student_answer, test_case_answer)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "2iSawxClehH3",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "e64031d2f9aa1de1eee0541aa66e0321",
          "grade": false,
          "grade_id": "cell-e2e22fe1d0b1b38d",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "### Task 1.4: Remove Stop Words (0.5 Marks)\n",
        "\n",
        "There are some commonly used words in a language like in case of english 'the', 'a', 'I', 'he' which might not provide much valuable information for the current task in hand, and hence can be removed from the text. Again for a task like POS Tagging (which we will see in the future assignments), this shouldn't be done but for sentiment classification the labels can be assumed to be largely independent of the presence of such words.\n",
        "\n",
        "The choice of the stop words to use can be subjective and in many cases might depend upon the problem in hand. For the purposes of this assignment we will consider the stop words for English language present in the `nltk` package. The code for obtaining these stop words is given in the following cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "deletable": false,
        "editable": false,
        "id": "EF2RUF-VhwgI",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "53ad13de4f03998d74885f8364e81301",
          "grade": false,
          "grade_id": "cell-def1061b193796df",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "outputId": "94f47f46-e4a8-49b5-87ea-af48a5696e67"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"i,me,my,myself,we,our,ours,ourselves,you,you're,you've,you'll,you'd,your,yours,yourself,yourselves,he,him,his,himself,she,she's,her,hers,herself,it,it's,its,itself,they,them,their,theirs,themselves,what,which,who,whom,this,that,that'll,these,those,am,is,are,was,were,be,been,being,have,has,had,having,do,does,did,doing,a,an,the,and,but,if,or,because,as,until,while,of,at,by,for,with,about,against,between,into,through,during,before,after,above,below,to,from,up,down,in,out,on,off,over,under,again,further,then,once,here,there,when,where,why,how,all,any,both,each,few,more,most,other,some,such,no,nor,not,only,own,same,so,than,too,very,s,t,can,will,just,don,don't,should,should've,now,d,ll,m,o,re,ve,y,ain,aren,aren't,couldn,couldn't,didn,didn't,doesn,doesn't,hadn,hadn't,hasn,hasn't,haven,haven't,isn,isn't,ma,mightn,mightn't,mustn,mustn't,needn,needn't,shan,shan't,shouldn,shouldn't,wasn,wasn't,weren,weren't,won,won't,wouldn,wouldn't\""
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "from nltk.corpus import stopwords\n",
        "STOPWORDS = stopwords.words(\"english\")\n",
        "\",\".join(STOPWORDS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "WBFQaRCJiOR8",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "266728e353be799a87caf12ecf7bd52d",
          "grade": false,
          "grade_id": "cell-c87968a6b3949535",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "As can be seen from the output above the stop words contain commonly used words that may not provide much information for the downstream task. Implement the function `remove_stop_words` below using the list of stop words given by `STOPWORDS` in the above cell.\n",
        "\n",
        "Note that the stop words list contains the words in lower case, so you might want to convert a word in the text to lower case using `to_lower_case` function that you implemented above, before checking if it is present in the stop words list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "id": "0Q3Px3ctiAhi",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "a525fffedbfdc7966926e56a3a3d5e6a",
          "grade": false,
          "grade_id": "cell-8bdbcd7ade04ace4",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "def remove_stop_words(text):\n",
        "    \"\"\" \n",
        "    Removes stop words given in `nltk.corpus.stopwords.words(\"english)` from a piece of text.\n",
        "\n",
        "    Parameters:\n",
        "    - text (str) : A Python string containing text from which stop words are to be removed\n",
        "\n",
        "    Returns:\n",
        "    - text_no_sw (str): Resulting string after removing stop words.\n",
        "\n",
        "    Hint: You should use `nltk_word_tokenize` for splitting the text\n",
        "        into words\n",
        "\n",
        "    \"\"\"\n",
        "    STOPWORDS = stopwords.words(\"english\")\n",
        "    text_no_sw = None\n",
        "\n",
        "    from nltk import word_tokenize\n",
        "    tokenized=word_tokenize(text)\n",
        "    text_no_sw=[words for words in tokenized if words not in STOPWORDS]\n",
        "    text_no_sw=' '.join(text_no_sw)\n",
        "\n",
        "    return text_no_sw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "deletable": false,
        "editable": false,
        "id": "BMJ5LXnBlTf6",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "fc51fe0889368be680a78e04e814fcea",
          "grade": true,
          "grade_id": "cell-cb3de644e9fed6ff",
          "locked": true,
          "points": 0.5,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "outputId": "7ac815c1-f897-4267-84d0-cc27ad6575ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Sample Test Cases\n",
            "Sample Test Case 1:\n",
            "Input: Mr. and Mrs. Dursley, of number four, Privet Drive, were proud to say that they were perfectly normal!\n",
            "Function Output: Mr. Mrs. Dursley , number four , Privet Drive , proud say perfectly normal !\n",
            "Expected Output: Mr. Mrs. Dursley , number four , Privet Drive , proud say perfectly normal !\n",
            "Test Case Passed :)\n",
            "**********************************\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"Running Sample Test Cases\")\n",
        "print(\"Sample Test Case 1:\")\n",
        "test_case = \"Mr. and Mrs. Dursley, of number four, Privet Drive, were proud to say that they were perfectly normal!\"\n",
        "test_case_answer = \"Mr. Mrs. Dursley , number four , Privet Drive , proud say perfectly normal !\"\n",
        "test_case_student_answer = remove_stop_words(test_case)\n",
        "assert evaluate_string_test_cases(test_case, test_case_student_answer, test_case_answer)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "Y7Gn_swUvdaM",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "8cee73a3f7f3a2b07a5894e9c242fee2",
          "grade": false,
          "grade_id": "cell-d4102ca807db93c8",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "### Task 1.5: Stemming (0.75 Marks)\n",
        "\n",
        "It can be often benificial to group together different inflections of a word into a single term. For eg. *organizes* and *organizing* are the morphological inflections of the word *organize*, and replacing the instances of *organizes* and *organizing* with *organize* in our text data can help us reduce the number of unique words in our vocabulary. Stemming is one such approach to reduce the inflectional forms into a common base form.\n",
        "\n",
        "One common way of performing steming over the words are the *Suffix Removal* algorithms, which involves removing certain suffixes from the word based on a pre-defined set of rules like:\n",
        "- If the word ends with 's' remove 's' (denoted as S-> ϵ.eg. plays -> play)\n",
        "- If the word ends with 'es' remove 'es' (denoted as ES-> ϵ. eg. mangoes -> mango).\n",
        "- If the word ends with 'ing' remove 'ing'. (denoted as ING -> ϵ. eg. enjoying  -> enjoying)\n",
        "- If the word ends with 'ly' remove 'ly'. (denoted as LY -> ϵ. eg. badly -> bad)\n",
        "\n",
        "There can be much more similar rules defined to design a sophisticated stemmer. For now we would want you to implement a simple stemmer that uses only these 4 rules to stem words in a sentence. Complete the `stem_word` and `stem_text` functions below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "id": "cXhjp85SLudH",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "eb9bb139543613657a31b6602884de66",
          "grade": false,
          "grade_id": "cell-1bc0ffe3cd1b08db",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "def stem_word(word):\n",
        "    \"\"\"\n",
        "    Give a word performs suffix removal stemming on it using the following 4 rules:\n",
        "    - S -> ϵ\n",
        "    - ES -> ϵ\n",
        "    - ING -> ϵ\n",
        "    - LY -> ϵ\n",
        "    If none of the four suffixes is to be found in the word, the it must be returned\n",
        "    as it is.\n",
        "    Parameters:\n",
        "    - word (str) : A python string representing the word to stemmed\n",
        "\n",
        "    Returns:\n",
        "    - stemmed_word (str): `word` after stemming\n",
        "\n",
        "    HINT: It is possible that two rules can be satisfied like for mangoes\n",
        "    both the first two rules are satisfied i.e. it ends with 'es' as well as 's'\n",
        "    In such cases consider the suffix with the larger length which is 'es'\n",
        "    in this case.\n",
        "    \"\"\"\n",
        "\n",
        "    stemmed_word = word\n",
        "\n",
        "    rules=['ing','ING','es','ES','ly','LY','s','S']\n",
        "    for rule in rules:\n",
        "        if rule in word[-len(rule):]:\n",
        "            stemmed_word= word[0:-len(rule)]\n",
        "            break\n",
        "    return stemmed_word\n",
        "\n",
        "\n",
        "\n",
        "def stem_text(text):\n",
        "    \"\"\"\n",
        "    Stems all the words in a piece of text, by calling `stem_word` for each word.\n",
        "\n",
        "    Parameters:\n",
        "    - text (str): A Python string containing text whose words are to be stemmed.\n",
        "\n",
        "    Returns:\n",
        "    - stemmed_text (str) : Resulting string after stemming.\n",
        "\n",
        "    HINT: You should use `nltk_word_tokenize` for splitting the text\n",
        "        into words\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    stemmed_text = None\n",
        "\n",
        "    from nltk import word_tokenize\n",
        "    words=word_tokenize(text)\n",
        "    stemmed_text=[stem_word(word) for word in words]\n",
        "    print(stemmed_text)\n",
        "    stemmed_text=' '.join(stemmed_text)\n",
        "    return stemmed_text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "deletable": false,
        "editable": false,
        "id": "bMfD5uUOO9NH",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "eb3176e2d18a9427636a04ebb7b36e9b",
          "grade": true,
          "grade_id": "cell-64ed84c6f02326a4",
          "locked": true,
          "points": 0.5,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "outputId": "a5940374-b88f-4328-bfca-ae65944d2653"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Sample Test Cases\n",
            "Sample Test Case 1:\n",
            "Input: mangoes\n",
            "Function Output: mango\n",
            "Expected Output: mango\n",
            "Test Case Passed :)\n",
            "**********************************\n",
            "\n",
            "Sample Test Case 2:\n",
            "Input: plays\n",
            "Function Output: play\n",
            "Expected Output: play\n",
            "Test Case Passed :)\n",
            "**********************************\n",
            "\n",
            "Sample Test Case 3:\n",
            "Input: enjoying\n",
            "Function Output: enjoy\n",
            "Expected Output: enjoy\n",
            "Test Case Passed :)\n",
            "**********************************\n",
            "\n",
            "Sample Test Case 4:\n",
            "Input: badly\n",
            "Function Output: bad\n",
            "Expected Output: bad\n",
            "Test Case Passed :)\n",
            "**********************************\n",
            "\n",
            "Sample Test Case 5:\n",
            "Input: fly\n",
            "Function Output: f\n",
            "Expected Output: f\n",
            "Test Case Passed :)\n",
            "**********************************\n",
            "\n",
            "Sample Test Case 6:\n",
            "Input: connection\n",
            "Function Output: connection\n",
            "Expected Output: connection\n",
            "Test Case Passed :)\n",
            "**********************************\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Sample test cases for `stem_word`\n",
        "\n",
        "print(\"Running Sample Test Cases\")\n",
        "print(\"Sample Test Case 1:\")\n",
        "test_case = \"mangoes\"\n",
        "test_case_answer = \"mango\"\n",
        "test_case_student_answer = stem_word(test_case)\n",
        "assert evaluate_string_test_cases(test_case, test_case_student_answer, test_case_answer)\n",
        "\n",
        "print(\"Sample Test Case 2:\")\n",
        "test_case = \"plays\"\n",
        "test_case_answer = \"play\"\n",
        "test_case_student_answer = stem_word(test_case)\n",
        "assert evaluate_string_test_cases(test_case, test_case_student_answer, test_case_answer)\n",
        "\n",
        "print(\"Sample Test Case 3:\")\n",
        "test_case = \"enjoying\"\n",
        "test_case_answer = \"enjoy\"\n",
        "test_case_student_answer = stem_word(test_case)\n",
        "assert evaluate_string_test_cases(test_case, test_case_student_answer, test_case_answer)\n",
        "\n",
        "print(\"Sample Test Case 4:\")\n",
        "test_case = \"badly\"\n",
        "test_case_answer = \"bad\"\n",
        "test_case_student_answer = stem_word(test_case)\n",
        "assert evaluate_string_test_cases(test_case, test_case_student_answer, test_case_answer)\n",
        "\n",
        "print(\"Sample Test Case 5:\")\n",
        "test_case = \"fly\"\n",
        "test_case_answer = \"f\"\n",
        "test_case_student_answer = stem_word(test_case)\n",
        "assert evaluate_string_test_cases(test_case, test_case_student_answer, test_case_answer)\n",
        "\n",
        "print(\"Sample Test Case 6:\")\n",
        "test_case = \"connection\"\n",
        "test_case_answer = \"connection\"\n",
        "test_case_student_answer = stem_word(test_case)\n",
        "assert evaluate_string_test_cases(test_case, test_case_student_answer, test_case_answer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "deletable": false,
        "editable": false,
        "id": "Fi5K6d_rS215",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "a808e9db159f82789a91920c862857bb",
          "grade": true,
          "grade_id": "cell-3cdab854aefe5efc",
          "locked": true,
          "points": 0.25,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "outputId": "d1d15580-c64e-4dee-bc1a-82fda43b97bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Test Case 1:\n",
            "['he', 'sit', 'and', 'eat', 'mango']\n",
            "Input: he sits and eats mangoes\n",
            "Function Output: he sit and eat mango\n",
            "Expected Output: he sit and eat mango\n",
            "Test Case Passed :)\n",
            "**********************************\n",
            "\n",
            "Sample Test Case 2:\n",
            "['he', 'wa', 'bad', 'hurt', 'after', 'play']\n",
            "Input: he was badly hurt after playing\n",
            "Function Output: he wa bad hurt after play\n",
            "Expected Output: he wa bad hurt after play\n",
            "Test Case Passed :)\n",
            "**********************************\n",
            "\n",
            "Sample Test Case 3:\n",
            "['f', 'my', 'little', 'bird']\n",
            "Input: fly my little birds\n",
            "Function Output: f my little bird\n",
            "Expected Output: f my little bird\n",
            "Test Case Passed :)\n",
            "**********************************\n",
            "\n",
            "Sample Test Case 4:\n",
            "['i', 'am', 'fac', 'a', 'poor', 'network', 'connection']\n",
            "Input: i am facing a poor network connection\n",
            "Function Output: i am fac a poor network connection\n",
            "Expected Output: i am fac a poor network connection\n",
            "Test Case Passed :)\n",
            "**********************************\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Sample test cases for `stem_text`\n",
        "\n",
        "print(\"Sample Test Case 1:\")\n",
        "test_case = \"he sits and eats mangoes\"\n",
        "test_case_answer = \"he sit and eat mango\"\n",
        "test_case_student_answer = stem_text(test_case)\n",
        "assert evaluate_string_test_cases(test_case, test_case_student_answer, test_case_answer)\n",
        "\n",
        "print(\"Sample Test Case 2:\")\n",
        "test_case = \"he was badly hurt after playing\"\n",
        "test_case_answer = \"he wa bad hurt after play\"\n",
        "test_case_student_answer = stem_text(test_case)\n",
        "assert evaluate_string_test_cases(test_case, test_case_student_answer, test_case_answer)\n",
        "\n",
        "print(\"Sample Test Case 3:\")\n",
        "test_case = \"fly my little birds\"\n",
        "test_case_answer = \"f my little bird\"\n",
        "test_case_student_answer = stem_text(test_case)\n",
        "assert evaluate_string_test_cases(test_case, test_case_student_answer, test_case_answer)\n",
        "\n",
        "print(\"Sample Test Case 4:\")\n",
        "test_case = \"i am facing a poor network connection\"\n",
        "test_case_answer = \"i am fac a poor network connection\"\n",
        "test_case_student_answer = stem_text(test_case)\n",
        "assert evaluate_string_test_cases(test_case, test_case_student_answer, test_case_answer)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "CPjMhPhHWvvV",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "de06287eb0d63dbb69bdc7d48bebe1c3",
          "grade": false,
          "grade_id": "cell-5ffdb99792619e58",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "As can be seen above the toy stemmer that we just implemented is not perfect. It is limited to the 4 rules so misses some obvious cases like reducing *connection* to *connect* or sometimes can over stem the word like for the word *fly* above is stemmed to `f` which loses the meaning of the original word. The more sophisticated algorithms use a bunch of rules and heuristics to avoid such situations. One of the most commonly used stemming algorithm is `Porter Stemmer`, which uses a 5 step procedure involving different suffix removal as well as modification rules to perform stemming. Interested students can read more about how Porter Stemmer works from [here](https://vijinimallawaarachchi.com/2017/05/09/porter-stemming-algorithm/). \n",
        "\n",
        "While implementing a sophisticated stemmer like Porter can be very complex, there are many python packages like *NLTK* (https://www.nltk.org/) that provide pre-implementations of a variety of stemming algorithms. Below we demonstrate how to implement `stem_word` function using different stemmers provided in NLTK."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "VD0PLF-WW8gQ",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "a2262957d811438e507714a86519a329",
          "grade": false,
          "grade_id": "cell-f17876e41b8b7d72",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "# Importing the stemmers from NLTK\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import LancasterStemmer\n",
        "from nltk.stem import SnowballStemmer\n",
        "def stem_word_with_nltk(word, stemmer_type = \"porter\"):\n",
        "\n",
        "  \"\"\"\n",
        "  Stems a word using Porter Stemmer from NLTK\n",
        "    - word (str) : A python string representing the word to be stemmed\n",
        "\n",
        "  Returns:\n",
        "    - stemmed_word (str): `word` after stemming\n",
        "  \"\"\"\n",
        "\n",
        "  # Initialize an object of the stemer class\n",
        "  if stemmer_type == \"porter\":\n",
        "    stemmer = PorterStemmer()\n",
        "  elif stemmer_type == \"lancaster\":\n",
        "    stemmer = LancasterStemmer()\n",
        "  elif stemmer_type == \"snowball\":\n",
        "    #Snowball stemmer works for multiple languages hence one should be specified during initialization\n",
        "    stemmer = SnowballStemmer(\"english\")\n",
        "  else:\n",
        "    stemmer = PorterStemmer()\n",
        "\n",
        "  # Call the `stem` method\n",
        "  stemmed_word = stemmer.stem(word)\n",
        "\n",
        "  return stemmed_word\n",
        "\n",
        "def stem_text_with_nltk(text, stemer_type = \"porter\"):\n",
        "\n",
        "  \"\"\"\n",
        "  Stems all the words in a piece of text using NLTK's stemers, by calling `stem_word_with_nltk` for each word.\n",
        "\n",
        "  Parameters:\n",
        "    - text (str): A Python string containing text whose words are to be stemmed.\n",
        "\n",
        "  Returns:\n",
        "    - stemmed_text (str) : Resulting string after stemming.\n",
        "\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  stemmed_text = None\n",
        "\n",
        "  stemmed_text = \" \".join([stem_word_with_nltk(word) for word in nltk_word_tokenize(text)])\n",
        "\n",
        "  return stemmed_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "deletable": false,
        "editable": false,
        "id": "vayPsP74Wm-R",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "29138a51033c7845825af0bc71ef1a4b",
          "grade": false,
          "grade_id": "cell-1085edc224703e7c",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "outputId": "1c1100fe-e054-48fd-ead8-1fcd44529b3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: connection\n",
            "Porter Stemmer Output: connect\n",
            "Lancaster Stemmer Output: connect\n",
            "Snowball Stemmer Output: connect\n",
            "*******************************************\n",
            "\n",
            "Input: fly\n",
            "Porter Stemmer Output: fli\n",
            "Lancaster Stemmer Output: fly\n",
            "Snowball Stemmer Output: fli\n",
            "*******************************************\n",
            "\n",
            "Input: happiness\n",
            "Porter Stemmer Output: happi\n",
            "Lancaster Stemmer Output: happy\n",
            "Snowball Stemmer Output: happi\n",
            "*******************************************\n",
            "\n",
            "Input: operational\n",
            "Porter Stemmer Output: oper\n",
            "Lancaster Stemmer Output: op\n",
            "Snowball Stemmer Output: oper\n"
          ]
        }
      ],
      "source": [
        "input = \"connection\"\n",
        "porter_output = stem_word_with_nltk(input, \"porter\")\n",
        "lancester_output = stem_word_with_nltk(input, \"lancaster\")\n",
        "snowball_output = stem_word_with_nltk(input, \"snowball\")\n",
        "\n",
        "print(f\"Input: {input}\")\n",
        "print(f\"Porter Stemmer Output: {porter_output}\")\n",
        "print(f\"Lancaster Stemmer Output: {lancester_output}\")\n",
        "print(f\"Snowball Stemmer Output: {snowball_output}\")\n",
        "\n",
        "print(\"*******************************************\\n\")\n",
        "\n",
        "input = \"fly\"\n",
        "porter_output = stem_word_with_nltk(input, \"porter\")\n",
        "lancester_output = stem_word_with_nltk(input, \"lancaster\")\n",
        "snowball_output = stem_word_with_nltk(input, \"snowball\")\n",
        "\n",
        "print(f\"Input: {input}\")\n",
        "print(f\"Porter Stemmer Output: {porter_output}\")\n",
        "print(f\"Lancaster Stemmer Output: {lancester_output}\")\n",
        "print(f\"Snowball Stemmer Output: {snowball_output}\")\n",
        "\n",
        "print(\"*******************************************\\n\")\n",
        "\n",
        "\n",
        "input = \"happiness\"\n",
        "porter_output = stem_word_with_nltk(input, \"porter\")\n",
        "lancester_output = stem_word_with_nltk(input, \"lancaster\")\n",
        "snowball_output = stem_word_with_nltk(input, \"snowball\")\n",
        "\n",
        "print(f\"Input: {input}\")\n",
        "print(f\"Porter Stemmer Output: {porter_output}\")\n",
        "print(f\"Lancaster Stemmer Output: {lancester_output}\")\n",
        "print(f\"Snowball Stemmer Output: {snowball_output}\")\n",
        "\n",
        "print(\"*******************************************\\n\")\n",
        "\n",
        "\n",
        "input = \"operational\"\n",
        "porter_output = stem_word_with_nltk(input, \"porter\")\n",
        "lancester_output = stem_word_with_nltk(input, \"lancaster\")\n",
        "snowball_output = stem_word_with_nltk(input, \"snowball\")\n",
        "\n",
        "print(f\"Input: {input}\")\n",
        "print(f\"Porter Stemmer Output: {porter_output}\")\n",
        "print(f\"Lancaster Stemmer Output: {lancester_output}\")\n",
        "print(f\"Snowball Stemmer Output: {snowball_output}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "3xj_15e-fuIA",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "e69a8e44d056643a9ff28b9bc6daa0bd",
          "grade": false,
          "grade_id": "cell-5155088a5f3f433d",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "As can be seen these stemmers are able to recognize various types of cases for stemming and can do a better job than our toy implementation. However, even these stemmers tend to make errors, like *operational* is reduced to *op* by Lancaster stemmer. This is because in the end stemming algorithms just use a bunch of heuristics to reduce the inflectional forms without any proper morphological analysis. **Lemmatization** is another common technique used to reduce different forms of a word to a common term called *lemma*, which makes use of a pre-defined vocabulary and morphological analysis of the words. Lemmatizers often work better when supplied with *Part of Speech tags* which we will be covering in the future assignments, so we will revisit Lemmatization later."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "giHvaqX-xbEA",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "c58774fc31f01fd6d0ace12479975c8f",
          "grade": false,
          "grade_id": "cell-66814cfdcf4a8510",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "### Task 1.6: Combine all preprocessing functions to a single pipeline (0.5 Marks)\n",
        "\n",
        "Now that we are done implementing the main preprocessing functions that might be useful for a text classification task, we can combine them into a single function that applies these 4 preprocessing techniques over a piece of text. We will then use this function to preprocess the movie reviews in our training and dev datasets.\n",
        "\n",
        "Implement the `preprocess_pipeline` and `preprocess_sentiment_data` functions below, where the former function combines the 4 preprocessing functions implemented above and the latter applies that to all the reviews in the dataset.\n",
        "\n",
        "Note: The order in which different preprocessing functions are to be applied can lead to different results. For eg. all of our stop words are in lower case hence before we remove them from the text we must make sure we have converted the text to lower case before hand. Please follow the following order for applying the preprocessing functions in your code:\n",
        "\n",
        "  1. to_lower_case\n",
        "  2. remove_punctuations\n",
        "  3. remove_stop_words\n",
        "  4. stem_text_with_nltk (call this with `stemer_type = \"porter\"`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "id": "dpZtpNXqdQJ1",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "afcc7d279bdb6229fdc9d772ba472567",
          "grade": false,
          "grade_id": "cell-e862d86747d6aba4",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "def preprocess_pipeline(text):\n",
        "\n",
        "    \"\"\"\n",
        "    Given a piece of text applies preprocessing techniques\n",
        "    like converting to lower case, removing stop words and punctuations,\n",
        "    and stemming.\n",
        "\n",
        "    Apply the functions in the following order:\n",
        "    1. to_lower_case\n",
        "    2. remove_punctuations\n",
        "    3. remove_stop_words\n",
        "    4. stem_text_with_nltk (call this with `stemer_type = \"porter\"`)\n",
        "\n",
        "    Inputs:\n",
        "    - text (str) : A python string containing text to be pre-processed\n",
        "\n",
        "    Returns:\n",
        "    - text_preprocessed (str) : Resulting string after applying preprocessing\n",
        "    \"\"\"\n",
        "\n",
        "    text_preprocessed = None\n",
        "\n",
        "\n",
        "    text_preprocessed=to_lower_case(text)\n",
        "    text_preprocessed=remove_punctuations(text_preprocessed)\n",
        "    text_preprocessed=remove_stop_words(text_preprocessed)\n",
        "    text_preprocessed=stem_text_with_nltk(text_preprocessed,stemer_type='porter')\n",
        "    return text_preprocessed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "deletable": false,
        "editable": false,
        "id": "mtrD4GXK3ZcB",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "1094f30d390f9701896b9fb39c009860",
          "grade": true,
          "grade_id": "cell-4b74127c07a2894d",
          "locked": true,
          "points": 0.25,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "outputId": "08088614-5312-4641-a730-5853d448f38d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Sample Test Cases\n",
            "Sample Test Case 1:\n",
            "Input: Mr. and Mrs. Dursley, of number four, Privet Drive, were proud to say that they were perfectly normal!\n",
            "Function Output: mr mr dursley number four privet drive proud say perfectli normal\n",
            "Expected Output: mr mr dursley number four privet drive proud say perfectli normal\n",
            "Test Case Passed :)\n",
            "**********************************\n",
            "\n",
            "Sample Test Case 2:\n",
            "Input: \"Little tyke,\" chortled Mr. Dursley as He left the house.\n",
            "Function Output: littl tyke chortl mr dursley left hous\n",
            "Expected Output: littl tyke chortl mr dursley left hous\n",
            "Test Case Passed :)\n",
            "**********************************\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"Running Sample Test Cases\")\n",
        "print(\"Sample Test Case 1:\")\n",
        "test_case = \"Mr. and Mrs. Dursley, of number four, Privet Drive, were proud to say that they were perfectly normal!\"\n",
        "test_case_answer = \"mr mr dursley number four privet drive proud say perfectli normal\"\n",
        "test_case_student_answer = preprocess_pipeline(test_case)\n",
        "assert evaluate_string_test_cases(test_case, test_case_student_answer, test_case_answer)\n",
        "\n",
        "print(\"Sample Test Case 2:\")\n",
        "test_case = \"\\\"Little tyke,\\\" chortled Mr. Dursley as He left the house.\"\n",
        "test_case_answer = \"littl tyke chortl mr dursley left hous\"\n",
        "test_case_student_answer = preprocess_pipeline(test_case)\n",
        "assert evaluate_string_test_cases(test_case, test_case_student_answer, test_case_answer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "id": "vHxSv9-FiRhA",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "9801f7a1726396409ab625a946959b78",
          "grade": false,
          "grade_id": "cell-910d9f1b54a3cc70",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "def preprocess_sentiment_data(df):\n",
        "    \"\"\"\n",
        "    Takes the pandas dataframe containing SST-2 data as input and applies\n",
        "    the `preprocess_pipeline` function to the its sentence column.\n",
        "\n",
        "    Inputs:\n",
        "    - df (pd.DataFrame): A pandas dataframe containing the SST-2 data with format:\n",
        "        | sentence  | label  |\n",
        "        ----------------------\n",
        "        | sentence_1| label_1|\n",
        "        | sentence_2| label_2|\n",
        "        | ..........| .......|\n",
        "        | ..........| .......|\n",
        "\n",
        "    Returns (pd.DataFrame):\n",
        "    - df_preprocessed: Resulting dataframe after applying `preprocessing_pipeline`\n",
        "    to the `sentence` column. Note that the column names of df_preprocessed\n",
        "    should be same as df and its should have the same number of rows as `df`.\n",
        "\n",
        "\n",
        "    Hint: Look up how to use `pd.DataFrame.apply` method in pandas\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    df_preprocessed = pd.DataFrame()\n",
        "    reviews=df['sentence'].values\n",
        "    df_preprocessed['sentence']=[preprocess_pipeline(sentence) for sentence in reviews]\n",
        "    df_preprocessed['label']=df['label']\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    return df_preprocessed\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "deletable": false,
        "editable": false,
        "id": "zjlOsHBpx7Oe",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "bce73167a1ee6813a7586a6c039be053",
          "grade": false,
          "grade_id": "cell-8c9d5693a8e93a17",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "outputId": "42136e73-40e6-4cf7-bf7a-a32aabb3cd51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                            sentence  label\n",
            "0                        hide new secret parent unit      0\n",
            "1                              contain wit labor gag      0\n",
            "2  love charact commun someth rather beauti human...      1\n",
            "3           remain utterli satisfi remain throughout      0\n",
            "4  worst revengeofthenerd cliché filmmak could dredg      0\n",
            "***************************\n",
            "                                            sentence  label\n",
            "0                         charm often affect journey      1\n",
            "1                         unflinchingli bleak desper      0\n",
            "2  allow us hope nolan pois embark major career c...      1\n",
            "3  act costum music cinematographi sound astound ...      1\n",
            "4                                          slow slow      0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Preprocess the train and test sets. This might take a few minutes\n",
        "train_df_preprocessed = preprocess_sentiment_data(train_df)\n",
        "test_df_preprocessed = preprocess_sentiment_data(test_df)\n",
        "print(train_df_preprocessed.head())\n",
        "print(\"***************************\")\n",
        "print(test_df_preprocessed.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "deletable": false,
        "editable": false,
        "id": "8hVfSsBy6zX8",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "12bb3ebb38da2bf3905f869940392fce",
          "grade": true,
          "grade_id": "cell-6e496720d48f93dd",
          "locked": true,
          "points": 0.25,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "outputId": "7720a060-ae45-40b2-a2ab-e460baef573b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Sample Test Cases\n",
            "Sample Test Case 1: Checking if the object returned is a pandas Dataframe\n",
            "Test Case Passed :)\n",
            "***********************************\n",
            "\n",
            "Sample Test Case 2: Checking if the returned dataframe has correct columns\n",
            "Test Case Passed :)\n",
            "***********************************\n",
            "\n",
            "Sample Test Case 3: Checking if the number of rows of the returned dataframe is same as the original dataframes\n",
            "Test Case Passed :)\n",
            "***********************************\n",
            "\n",
            "Sample Test Case 4: Checking if the returned dataframe has sentences preprocessed\n",
            "Input: contains no wit , only labored gags \n",
            "Function Output: contain wit labor gag\n",
            "Expected Output: contain wit labor gag\n",
            "Test Case Passed :)\n",
            "**********************************\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"Running Sample Test Cases\")\n",
        "print(\"Sample Test Case 1: Checking if the object returned is a pandas Dataframe\")\n",
        "assert isinstance(train_df_preprocessed, pd.DataFrame)\n",
        "print(\"Test Case Passed :)\")\n",
        "print(\"***********************************\\n\")\n",
        "\n",
        "print(\"Sample Test Case 2: Checking if the returned dataframe has correct columns\")\n",
        "student_column_names = sorted(list(train_df_preprocessed.columns))\n",
        "expected_column_names = [\"label\", \"sentence\"]\n",
        "\n",
        "assert student_column_names == expected_column_names\n",
        "print(\"Test Case Passed :)\")\n",
        "print(\"***********************************\\n\")\n",
        "\n",
        "print(\"Sample Test Case 3: Checking if the number of rows of the returned dataframe is same as the original dataframes\")\n",
        "assert len(train_df) == len(train_df_preprocessed) and len(test_df) == len(test_df_preprocessed)\n",
        "print(\"Test Case Passed :)\")\n",
        "print(\"***********************************\\n\")\n",
        "print(\"Sample Test Case 4: Checking if the returned dataframe has sentences preprocessed\")\n",
        "\n",
        "student_output = train_df_preprocessed[\"sentence\"].values[1]\n",
        "expected_output = \"contain wit labor gag\"\n",
        "assert evaluate_string_test_cases(train_df[\"sentence\"].values[1], student_output, expected_output)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "XzbDxFiUgut9",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "fe69d8075ade7cb0999904cfa56c20c5",
          "grade": false,
          "grade_id": "cell-2d3b021cb109b69d",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "## Task 2: Bag Of Word Models for Text Classification (1.75 Marks)\n",
        "\n",
        "Now that we are done with preprocessing the reviews in our datasets, we can begin building a classifier to classify them into positive or negative sentiment.\n",
        "\n",
        "As you might have studied in your Machine Learning courses, typical ML models work on the data described using mathematical objects like vectors and matrices, which are often referred to as features. These features can be of different types depending upon the downstream application, like for building a classifier to predict whether to give credit to a customer we might consider features like their age, income, employement status etc. In the same way to build a classifier for textual data, we need a way to describe each text example in terms of numeric features which can then be fed to the classification algorithm of our choice.\n",
        "\n",
        "Bag of Words model is one of the simplest but surprisingly effective way to represent text data for building Machine Learning models. In bag of words, occurence (or frequency) of each word in a given text example is defined as a feature for training the classifier. The order in which these words occur in the text is not relevant and we are just concerned with which words are present in the text. Consider the following example to understand how bag of words are used to represent text.\n",
        "\n",
        "As an example consider we have 2 examples present in our dataset:\n",
        "\n",
        "x1: john likes to watch movies mary likes movies too\n",
        "\n",
        "x2: mary also likes to watch football games\n",
        "\n",
        "Based on these two documents we can get the list of all words that occur in this dataset which will be:\n",
        "\n",
        "| index | word     |\n",
        "|-------|----------|\n",
        "| 0     | also     |\n",
        "| 1     | football |\n",
        "| 2     | games    |\n",
        "| 3     | john     |\n",
        "| 4     | likes    |\n",
        "| 5     | mary     |\n",
        "| 6     | movies   |\n",
        "| 7     | to       |\n",
        "| 8     | too      |\n",
        "| 9     | watch    |\n",
        "\n",
        "We can then define features for the two x1 and x2 as follows:\n",
        "\n",
        "\n",
        "|    | also | football | games | john | likes | mary | movies | to | too | watch |\n",
        "|----|------|----------|-------|------|-------|------|--------|----|-----|-------|\n",
        "| x1 | 0    | 0        | 0     | 1    | 2     | 1    | 2      | 1  | 2   | 1     |\n",
        "| x2 | 1    | 1        | 1     | 0    | 1     | 1    | 0      | 0  | 0   | 0     |\n",
        "\n",
        "These features can then be used to train an ML model. To summarize the following two steps must be followed to create bag of word representations of the text examples in a dataset.\n",
        "\n",
        "- Step 1: Create a word vocabulary by iterating through all the documents in the **training** dataset, storing all the unique words that are present in each document. Also maintain mappings to map each word to an index and vice-versa, which we will need to define values for each feature dimension.\n",
        "\n",
        "- Step 2: For each document in the training and test sets, get the frequency of each word in our vocabulary and use it to define feature for that example. \n",
        "\n",
        "Below you will implement functions to create bag of words representations of the dataset examples\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "UWPxJNLMwMyu",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "99b95111d61df2a70bc726ad0846fab0",
          "grade": false,
          "grade_id": "cell-761f58e096b7331e",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "### Task 2.1: Create vocabularies (0.5 Marks)\n",
        "\n",
        "As described above our first step will be to create word vocabulary for the documents in our dataset. Implement `create_vocab` function below which takes as input a list of documents and creates a list of unique words that occur in them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "id": "CtE_uIoVqIj0",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "6f3f3a1bd62b411ab7eb35e27478d7b7",
          "grade": false,
          "grade_id": "cell-1d86cd6bcfca9df9",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "def create_vocab(documents):\n",
        "    \"\"\"\n",
        "    Given a list of documents each represented as a string,\n",
        "    create a word vocabulary containing all the words that occur\n",
        "    in these documents.\n",
        "\n",
        "    Inputs:\n",
        "    - documents (list) : A list with each element as a string representing a\n",
        "    document.\n",
        "\n",
        "    Returns:\n",
        "    - vocab (list) : A **sorted** list containing all unique words in the\n",
        "    documents\n",
        "\n",
        "    Example Input: ['john likes to watch movies mary likes movies too',\n",
        "                  'mary also likes to watch football games']\n",
        "\n",
        "    Expected Output: ['also',\n",
        "                    'football',\n",
        "                    'games',\n",
        "                    'john',\n",
        "                    'likes',\n",
        "                    'mary',\n",
        "                    'movies',\n",
        "                    'to',\n",
        "                    'too',\n",
        "                    'watch']\n",
        "\n",
        "\n",
        "    Hint: `nltk_word_tokenize` function may come in handy\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    vocab = []\n",
        "    from nltk import word_tokenize\n",
        "    for sentence in documents:\n",
        "        tokens=list(set(list(word_tokenize(sentence))))\n",
        "        vocab=list(set(vocab+tokens))\n",
        "        \n",
        "        \n",
        "\n",
        "    return sorted(vocab) # Don't change this"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "deletable": false,
        "editable": false,
        "id": "VV9gzaGM80ad",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "b743ca10fb0bb9a5089d2784801b5445",
          "grade": true,
          "grade_id": "cell-93811b38a1766d53",
          "locked": true,
          "points": 0.5,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "outputId": "1b00c655-4122-43b2-fb5b-2a8cbf147d20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Sample Test Cases\n",
            "Sample Test Case 1:\n",
            "Input: ['john likes to watch movies mary likes movies too', 'mary also likes to watch football games']\n",
            "Function Output: ['also', 'football', 'games', 'john', 'likes', 'mary', 'movies', 'to', 'too', 'watch']\n",
            "Expected Output: ['also', 'football', 'games', 'john', 'likes', 'mary', 'movies', 'to', 'too', 'watch']\n",
            "Test Case Passed :)\n",
            "**********************************\n",
            "\n",
            "Sample Test Case 2:\n",
            "Input: ['We all live in a yellow submarine.', 'Yellow submarine, yellow submarine!!']\n",
            "Function Output: ['!', ',', '.', 'We', 'Yellow', 'a', 'all', 'in', 'live', 'submarine', 'yellow']\n",
            "Expected Output: ['!', ',', '.', 'We', 'Yellow', 'a', 'all', 'in', 'live', 'submarine', 'yellow']\n",
            "Test Case Passed :)\n",
            "**********************************\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"Running Sample Test Cases\")\n",
        "print(\"Sample Test Case 1:\")\n",
        "\n",
        "test_case = [\"john likes to watch movies mary likes movies too\",\n",
        "              \"mary also likes to watch football games\"]\n",
        "test_case_answer = ['also', 'football', 'games', 'john', 'likes', 'mary', 'movies', 'to', 'too', 'watch']\n",
        "test_case_student_answer = create_vocab(test_case)\n",
        "assert evaluate_list_test_cases(test_case, test_case_student_answer, test_case_answer)\n",
        "\n",
        "print(\"Sample Test Case 2:\")\n",
        "\n",
        "test_case = [\"We all live in a yellow submarine.\",\n",
        "             \"Yellow submarine, yellow submarine!!\"\n",
        "             ]\n",
        "test_case_answer = ['!', ',', '.', 'We', 'Yellow', 'a', 'all', 'in', 'live', 'submarine', 'yellow']\n",
        "test_case_student_answer = create_vocab(test_case)\n",
        "assert evaluate_list_test_cases(test_case, test_case_student_answer, test_case_answer)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "N4d5FU_11Xc9",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "b25e5300ef54deef5ba9b38a4a3c9fb4",
          "grade": false,
          "grade_id": "cell-d6ece6cd0f7791ad",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "Note the output of sample test case 2 contains punctuations as well as different upper-case and lower-case variants of a word detected as seperate words. This illustrates the importance of performing the preprocessing over the documents as it reduces the unecessary words like punctuations, stop words in the vocablary as well as help provide a common term to different variants of a word."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "deletable": false,
        "editable": false,
        "id": "gghG6ybs0sSn",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "1a50d60e2d934f116db8e73ee046cdde",
          "grade": false,
          "grade_id": "cell-16a71f3a50681f1b",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "outputId": "6db24f0a-672b-47e0-ea5b-d97006466b71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Vocabulary Created. Number of words: 10781\n"
          ]
        }
      ],
      "source": [
        "# Now that our `create_vocab` function is ready, let's create vocabulary for the SST dataset\n",
        "\n",
        "train_documents = train_df_preprocessed[\"sentence\"].values.tolist() # Note that we are selecting preprocessed documents\n",
        "train_vocab = create_vocab(train_documents)\n",
        "\n",
        "print(f\"Training Vocabulary Created. Number of words: {len(train_vocab)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "duY4XnCV5-Rv",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "3ea4c50a6ab585e8f222ed14db310752",
          "grade": false,
          "grade_id": "cell-87821ca15761432a",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "### Task 2.2: Create word to index mapping (0.25 Marks)\n",
        "Now that we have a list of words in our dataset, we can map each word to an index which will be useful to represent what word each feature dimension refers to. Implement the `get_word_idx_mappings` function below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "id": "caT93EMH5Tfx",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "d7c8253b149acf49c98231cdab9c3c52",
          "grade": false,
          "grade_id": "cell-832da6a1aea10989",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "def get_word_idx_mapping(vocab):\n",
        "\n",
        "    \"\"\"\n",
        "    Give a list of strings each representing a word in the vocabulary\n",
        "    creates a dictionary that maps each word in the list to its\n",
        "    corresponding index.\n",
        "\n",
        "    Inputs:\n",
        "    - vocab (list): A list of strings each representing a word in the vocabulary\n",
        "\n",
        "    Outputs:\n",
        "    - word2idx (dict): A Python dictionary mapping each word to its index in vocabulary\n",
        "\n",
        "    Example Input: ['also',\n",
        "                    'football',\n",
        "                    'games',\n",
        "                    'john',\n",
        "                    'likes',\n",
        "                    'mary',\n",
        "                    'movies',\n",
        "                    'to',\n",
        "                    'too',\n",
        "                    'watch']\n",
        "\n",
        "    Expected Output: {'also': 0,\n",
        "                  'football': 1,\n",
        "                  'games': 2,\n",
        "                  'john': 3,\n",
        "                  'likes': 4,\n",
        "                  'mary': 5,\n",
        "                  'movies': 6,\n",
        "                  'to': 7,\n",
        "                  'too': 8,\n",
        "                  'watch': 9}\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    word2idx = {}\n",
        "\n",
        "    word2idx={word:idx for idx,word in enumerate(vocab)}\n",
        "\n",
        "    return word2idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "deletable": false,
        "editable": false,
        "id": "80IR-BKZ8u4d",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "c1af4dd53a33d04409b85a77a6e99b53",
          "grade": true,
          "grade_id": "cell-aac76832a8b468b7",
          "locked": true,
          "points": 0.25,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "outputId": "ec26659e-afa5-4722-9b65-9808e274fc50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Sample Test Cases\n",
            "Sample Test Case 1:\n",
            "Input: ['also', 'football', 'games', 'john', 'likes', 'mary', 'movies', 'to', 'too', 'watch']\n",
            "Function Output: {'also': 0, 'football': 1, 'games': 2, 'john': 3, 'likes': 4, 'mary': 5, 'movies': 6, 'to': 7, 'too': 8, 'watch': 9}\n",
            "Expected Output: {'also': 0, 'football': 1, 'games': 2, 'john': 3, 'likes': 4, 'mary': 5, 'movies': 6, 'to': 7, 'too': 8, 'watch': 9}\n",
            "Test Case Passed :)\n",
            "**********************************\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"Running Sample Test Cases\")\n",
        "print(\"Sample Test Case 1:\")\n",
        "test_case = ['also', 'football', 'games', 'john', 'likes', 'mary', 'movies', 'to', 'too', 'watch']\n",
        "test_case_answer = {'also': 0, 'football': 1, 'games': 2, 'john': 3, 'likes': 4, 'mary': 5, 'movies': 6, 'to': 7, 'too': 8, 'watch': 9}\n",
        "test_case_student_answer = get_word_idx_mapping(test_case)\n",
        "assert evaluate_list_test_cases(test_case, test_case_student_answer, test_case_answer)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "55-NnrC39qgd",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "d4680e268db8929fe98bcf6dbb68ff6a",
          "grade": false,
          "grade_id": "cell-9e6028db09fce23c",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "## Task 2.3: Create Bag of word features for the documents (1 Mark)\n",
        "\n",
        "Now that we have the list of words and a word to index mapping we can create a bag of word feature vector for each of the document present in training and test data. Implement the function `get_document_bow_feature` that takes as an input a document, a vocabulary, and a vocabulary to index mapping, and returns the feature vector for the document."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "deletable": false,
        "id": "LoauVlK29n1c",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "9f812ad1236d5a7482f5ccb073785903",
          "grade": false,
          "grade_id": "cell-418f7d59edb65074",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "def get_document_bow_feature(document, vocab, word2idx):\n",
        "    \"\"\"\n",
        "    Given a string representing the document and the vocabulary, create a bag of\n",
        "    words representation of the document i.e. a feature vector where each feature\n",
        "    is defined as the frequency of each word in the vocabulary.\n",
        "\n",
        "    Inputs:\n",
        "    - document (str): A python string representing the document for which features are to be obtained\n",
        "    - vocab (list): A list of words present in the vocabulary\n",
        "    - word2idx (dict): A dictionary that maps each word to an index.\n",
        "\n",
        "    Returns:\n",
        "    - bow_feature (numpy.ndarray): A numpy array of size `len(vocab)` whose each element contains the count of each word in the vocabulary.\n",
        "\n",
        "    Example Input:\n",
        "    document = \"john likes to watch movies mary likes movies too\"\n",
        "    vocab = ['also','football','games','john','likes','mary', 'movies','to','too','watch']\n",
        "    word2idx = {'also': 0, 'football': 1, 'games': 2, 'john': 3, 'likes': 4, 'mary': 5, 'movies': 6, 'to': 7, 'too': 8, 'watch': 9}\n",
        "\n",
        "    Expected Output: array([0, 0, 0, 1, 2, 1, 2, 1, 1, 1])\n",
        "\n",
        "    \"\"\"\n",
        "    bow_feature = np.zeros(len(vocab))\n",
        "    from nltk import word_tokenize\n",
        "    tokens=word_tokenize(document)\n",
        "    for word in tokens:\n",
        "        try:\n",
        "          bow_feature[word2idx[word]]+=1\n",
        "        except:\n",
        "          pass\n",
        "    return bow_feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "deletable": false,
        "editable": false,
        "id": "a1JpF6sdB__c",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "67be1e9a6523f4c2422d7108f65361c4",
          "grade": true,
          "grade_id": "cell-d45f4eb621fbd845",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "outputId": "2870f874-19e0-49e0-96fe-fc4067585308"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Sample Test Cases\n",
            "Sample Test Case 1:\n",
            "Input: {'document': 'john likes to watch movies mary likes movies too', 'vocab': ['also', 'football', 'games', 'john', 'likes', 'mary', 'movies', 'to', 'too', 'watch'], 'word2idx': {'also': 0, 'football': 1, 'games': 2, 'john': 3, 'likes': 4, 'mary': 5, 'movies': 6, 'to': 7, 'too': 8, 'watch': 9}}\n",
            "Function Output: [0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0]\n",
            "Expected Output: [0, 0, 0, 1, 2, 1, 2, 1, 1, 1]\n",
            "Test Case Passed :)\n",
            "**********************************\n",
            "\n",
            "Sample Test Case 2:\n",
            "Input: {'document': 'mary also likes to watch football games', 'vocab': ['also', 'football', 'games', 'john', 'likes', 'mary', 'movies', 'to', 'too', 'watch'], 'word2idx': {'also': 0, 'football': 1, 'games': 2, 'john': 3, 'likes': 4, 'mary': 5, 'movies': 6, 'to': 7, 'too': 8, 'watch': 9}}\n",
            "Function Output: [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0]\n",
            "Expected Output: [1, 1, 1, 0, 1, 1, 0, 1, 0, 1]\n",
            "Test Case Passed :)\n",
            "**********************************\n",
            "\n",
            "Sample Test Case 3:\n",
            "Input: {'document': 'mary and jane also like to watch football games', 'vocab': ['also', 'football', 'games', 'john', 'likes', 'mary', 'movies', 'to', 'too', 'watch'], 'word2idx': {'also': 0, 'football': 1, 'games': 2, 'john': 3, 'likes': 4, 'mary': 5, 'movies': 6, 'to': 7, 'too': 8, 'watch': 9}}\n",
            "Function Output: [1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0]\n",
            "Expected Output: [1, 1, 1, 0, 0, 1, 0, 1, 0, 1]\n",
            "Test Case Passed :)\n",
            "**********************************\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"Running Sample Test Cases\")\n",
        "print(\"Sample Test Case 1:\")\n",
        "test_case = {\"document\": \"john likes to watch movies mary likes movies too\",\n",
        "             \"vocab\": ['also', 'football', 'games', 'john', 'likes', 'mary', 'movies', 'to', 'too', 'watch'],\n",
        "             \"word2idx\": {'also': 0, 'football': 1, 'games': 2, 'john': 3, 'likes': 4, 'mary': 5, 'movies': 6, 'to': 7, 'too': 8, 'watch': 9}\n",
        "             }\n",
        "test_case_answer = np.array([0, 0, 0, 1, 2, 1, 2, 1, 1, 1])\n",
        "test_case_student_answer = get_document_bow_feature(**test_case)\n",
        "assert evaluate_list_test_cases(test_case, test_case_student_answer.tolist(), test_case_answer.tolist())\n",
        "\n",
        "print(\"Sample Test Case 2:\")\n",
        "test_case = {\"document\": \"mary also likes to watch football games\",\n",
        "             \"vocab\": ['also', 'football', 'games', 'john', 'likes', 'mary', 'movies', 'to', 'too', 'watch'],\n",
        "             \"word2idx\": {'also': 0, 'football': 1, 'games': 2, 'john': 3, 'likes': 4, 'mary': 5, 'movies': 6, 'to': 7, 'too': 8, 'watch': 9}\n",
        "             }\n",
        "test_case_answer = np.array([1, 1, 1, 0, 1, 1, 0, 1, 0, 1])\n",
        "test_case_student_answer = get_document_bow_feature(**test_case)\n",
        "assert evaluate_list_test_cases(test_case, test_case_student_answer.tolist(), test_case_answer.tolist())\n",
        "\n",
        "print(\"Sample Test Case 3:\")\n",
        "test_case = {\"document\": \"mary and jane also like to watch football games\",\n",
        "             \"vocab\": ['also', 'football', 'games', 'john', 'likes', 'mary', 'movies', 'to', 'too', 'watch'],\n",
        "             \"word2idx\": {'also': 0, 'football': 1, 'games': 2, 'john': 3, 'likes': 4, 'mary': 5, 'movies': 6, 'to': 7, 'too': 8, 'watch': 9}\n",
        "             }\n",
        "test_case_answer = np.array([1, 1, 1, 0, 0, 1, 0, 1, 0, 1])\n",
        "test_case_student_answer = get_document_bow_feature(**test_case)\n",
        "assert evaluate_list_test_cases(test_case, test_case_student_answer.tolist(), test_case_answer.tolist())\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "cM4Of6HOIvf5",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "3d12c868923719f499525e50c8abdc1b",
          "grade": false,
          "grade_id": "cell-90d4b81b34e40d26",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "Now that our `get_document_bow_feature` function seems to work properly, let's get bag of word features for the examples in our datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "deletable": false,
        "editable": false,
        "id": "o5dPduZoIty6",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "f4511d6950bcf7f52e7a048ec24c8212",
          "grade": false,
          "grade_id": "cell-7c94a44d91cfadb3",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "outputId": "508544b8-7fad-4e34-9c81-b8e0a95f0cea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hide new secret parent unit\n",
            "Length of bow feature: 10781\n",
            "Number of non-zero entries in the bow feature: 5\n"
          ]
        }
      ],
      "source": [
        "# Getting bow feature for one training document first\n",
        "training_example = train_documents[0]\n",
        "bow_feature = get_document_bow_feature(training_example,\n",
        "                                       train_vocab,\n",
        "                                       train_vocab2idx)\n",
        "print(f\"Length of bow feature: {len(bow_feature)}\")\n",
        "print(f\"Number of non-zero entries in the bow feature: {len(bow_feature[bow_feature != 0])}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "z4WgKREUJmlC",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "604e1988f7d9710a2ae87b96827fd2b4",
          "grade": false,
          "grade_id": "cell-90aeadd30f0658df",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "As you can see, since our vocabulary size is 10781, bag of words vectors for each document will be of size 10781. Since we have about 67k training examples, it won't be practical to store these high dimensional vectors as it is for all the documents. Instead of storing the features for all the documents in memory, we query the features while training the model in a batch wise fashion i.e. at a time we train on N examples, such that N <<< 10781. This will be more clear when we discuss creating datasets and dataloaders in the next part."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "9sxGKKCTwdzr",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "b1e1f76faa0a64113b1253c814fe268e",
          "grade": false,
          "grade_id": "cell-845b66f6ad9eba70",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "## Task 3: Training a Linear Classifier using Bag of Words Features (5.25 Marks)\n",
        "\n",
        "Now that we have defined our numerical features to represent each of the documents, we can start training a classifier on top of it. For the purposes of this assignment we will be implementing a linear classifier namely **Logistic Regression**. We assume that you have studied logistic regression in your Machine Learning course. For a recap of the same you can refer to these [videos](https://www.youtube.com/watch?v=-la3q9d7AKQ&list=PLLssT5z_DsK-h9vYZkQkYNWcItqhlRJLN&index=32).\n",
        "\n",
        "We will be using Pytorch to implement and train our logistic regression classifier for the sentiment prediction task. We start by implementing the dataset and dataloaders to iterate over the dataset, and then we move to defining the logistic regression module, the cross entropy loss function and an optimizer for training the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "JFj2z-3K0L91",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "8d67a8dcd0ca55603c76e621c767e067",
          "grade": false,
          "grade_id": "cell-f297dd9e6d90ed73",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "### Task 3.1: Defining Pytorch Dataset and Dataloaders to iterate over the SST-Dataset (0.5 Marks)\n",
        "\n",
        "Often while training neural networks or in our case linear classifiers, it is not practical to train over the entire dataset at once, and instead we use a batch wise training strategy, where we iterate over different batches of the dataset. Hence, it is useful to define iterators for doing the same. Defining pipelines for processing data samples and then writing iterators on top of that can often be very messy. Pytorch provides `torch.utils.data.Dataset` and `torch.utils.data.Dataloader` classes that make it much more convenient to do the same in a modular fashion.\n",
        "\n",
        "`torch.utils.data.Dataset` provides a wrapper to store our dataset, which can then be used by `torch.utils.data.Dataloader` to define an iterable over the dataset. To learn more about Dataset and Dataloader classes, please refer to the tutorial [here](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html)\n",
        "\n",
        "We start by defining a custom Dataset class for our dataset by extending the `torch.utils.data.Dataset` class. A custom Dataset class must implement three functions:\n",
        "-  `__init__`: This is the constructor for our custom class, and is often used to store the (meta)data, which can then be used by the other functions to create samples of the dataset.\n",
        "- `__len__`: This method returns the number of examples present in the dataset.\n",
        "-  `__getitem__`: This method loads and returns a sample stored at the given index `idx`  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "id": "f_FthraCDbM8",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "1a01ff64d41c5e7a9fc1e3342a9b42da",
          "grade": false,
          "grade_id": "cell-924f8c8e69440c91",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "\n",
        "class SST2Dataset(Dataset):\n",
        "\n",
        "  def __init__(self, documents, labels, vocab, word2idx):\n",
        "    \"\"\"\n",
        "    Store dataset documents and labels here so that they can be used by\n",
        "    __getitem__ to process and return the samples.\n",
        "\n",
        "    Inputs:\n",
        "      - documents (list): A list of strings containing reviews in our dataset.\n",
        "      - labels (list): A list of sentiment labels (1 or 0) corresponding to each document.\n",
        "      - vocab (list): A list of words present in the vocabulary\n",
        "      - word2idx (dict): A dictionary that maps each word to an index.\n",
        "    \"\"\"\n",
        "\n",
        "    self.documents = documents\n",
        "    self.labels = labels\n",
        "    self.vocab = vocab\n",
        "    self.word2idx = word2idx\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.documents)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    \"\"\"\n",
        "    Loads and returns the features and label corresponding to the `idx` index\n",
        "    in the documents and labels lists.\n",
        "\n",
        "    Inputs:\n",
        "      - idx (index): Index of the dataset example to be loaded and returned\n",
        "\n",
        "    Returns:\n",
        "      - features (numpy.ndarray): The bag of word features corresponding the document indexed by `idx`\n",
        "      - label (int): The sentiment label for the `idx`th document\n",
        "\n",
        "    Hint: You can get the document and label by doing self.documents[idx],\n",
        "    self.labels[idx]. Features of the document are to be extracted via\n",
        "    `get_document_bow_feature` function\n",
        "    \"\"\"\n",
        "\n",
        "    features, label = None, None\n",
        "    features=get_document_bow_feature(self.documents[idx],self.vocab,self.word2idx)\n",
        "    label=self.labels[idx]\n",
        "    return features, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "deletable": false,
        "editable": false,
        "id": "IKpOKip1OqCz",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "bcba45614455a3ded0a772ecb7df8ecc",
          "grade": true,
          "grade_id": "cell-25ef123969040228",
          "locked": true,
          "points": 0.5,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "outputId": "ebe79104-94d4-495a-8a4c-266d426f84c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Sample Test Cases\n",
            "this movie is great\n",
            "Sample Test Case 1: Testing Returned Labels for idx = 0\n",
            "Output Label: 0\n",
            "Expected Label: 0\n",
            "**********************************\n",
            "\n",
            "Sample Test Case 2: Testing returned Features for idx = 0\n",
            "Output Features: [0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0]\n",
            "Expected Features: [0, 0, 0, 1, 1, 1, 1]\n",
            "I HATED this film\n",
            "**********************************\n",
            "\n",
            "Sample Test Case 3: Testing Returned Labels for idx = 1\n",
            "Output Label: 1\n",
            "Expected Label: 1\n",
            "**********************************\n",
            "\n",
            "Sample Test Case 4: Testing returned Features for idx = 1\n",
            "Output Features: [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0]\n",
            "Expected Features: [1, 1, 1, 0, 0, 0, 1]\n",
            "**********************************\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"Running Sample Test Cases\")\n",
        "\n",
        "sample_documents = [\"this movie is great\",\n",
        "                    \"I HATED this film\"]\n",
        "sample_labels = [0, 1]\n",
        "sample_vocab = create_vocab(sample_documents)\n",
        "sample_word2idx = get_word_idx_mapping(sample_vocab)\n",
        "sample_dataset = SST2Dataset(sample_documents, sample_labels,\n",
        "                             sample_vocab, sample_word2idx)\n",
        "\n",
        "test_case_idx = 0\n",
        "features, label = sample_dataset.__getitem__(test_case_idx)\n",
        "\n",
        "print(f\"Sample Test Case 1: Testing Returned Labels for idx = {test_case_idx}\")\n",
        "print(f\"Output Label: {label}\")\n",
        "print(f\"Expected Label: {sample_labels[test_case_idx]}\")\n",
        "assert label == sample_labels[test_case_idx]\n",
        "print(\"**********************************\\n\")\n",
        "\n",
        "print(f\"Sample Test Case 2: Testing returned Features for idx = {test_case_idx}\")\n",
        "expected_features = [0, 0, 0, 1, 1, 1, 1]\n",
        "\n",
        "print(f\"Output Features: {features.tolist()}\")\n",
        "print(f\"Expected Features: {expected_features}\")\n",
        "assert expected_features == features.tolist()\n",
        "\n",
        "test_case_idx = 1\n",
        "features, label = sample_dataset.__getitem__(test_case_idx)\n",
        "print(\"**********************************\\n\")\n",
        "\n",
        "print(f\"Sample Test Case 3: Testing Returned Labels for idx = {test_case_idx}\")\n",
        "print(f\"Output Label: {label}\")\n",
        "print(f\"Expected Label: {sample_labels[test_case_idx]}\")\n",
        "assert label == sample_labels[test_case_idx]\n",
        "print(\"**********************************\\n\")\n",
        "\n",
        "print(f\"Sample Test Case 4: Testing returned Features for idx = {test_case_idx}\")\n",
        "expected_features = [1, 1, 1, 0, 0, 0, 1]\n",
        "print(f\"Output Features: {features.tolist()}\")\n",
        "print(f\"Expected Features: {expected_features}\")\n",
        "assert expected_features == features.tolist()\n",
        "print(\"**********************************\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "Np8tcm0mUpG9",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "45c3a4be7aa2ab982a4806ccd76d3483",
          "grade": false,
          "grade_id": "cell-7a79bd8f8e1ddc4d",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "Now that the custom class SST2Dataset seems to working fine we can create objects for our training and test datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "c5kFDYDpUCbi",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "d511e67cde7eaad85299c3d1c6f61900",
          "grade": false,
          "grade_id": "cell-3d4fb6f323f29364",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "# Get documents and labels from the dataset\n",
        "train_documents = train_df_preprocessed[\"sentence\"].values.tolist()\n",
        "train_labels = train_df[\"label\"].values.tolist()\n",
        "test_documents = test_df_preprocessed[\"sentence\"].values.tolist()\n",
        "test_labels = test_df[\"label\"].values.tolist()\n",
        "\n",
        "# Create vocabulary from training data\n",
        "train_vocab = create_vocab(train_documents)\n",
        "train_word2idx = get_word_idx_mapping(train_vocab)\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = SST2Dataset(train_documents,\n",
        "                            train_labels,\n",
        "                            train_vocab,\n",
        "                            train_word2idx)\n",
        "test_dataset = SST2Dataset(test_documents,\n",
        "                           test_labels,\n",
        "                           train_vocab,\n",
        "                           train_word2idx\n",
        "                           )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "GfSYJmHoV1o8",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "be4a0ad98f1734f3a8dfa1a7df38ab94",
          "grade": false,
          "grade_id": "cell-9fd000c069aa4c09",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "Notice how we used training data vocabulary for creating test dataset as well. Can you tell why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "oLnu4s83V_Qj",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "a3ca003dc648aba52cad73ee376934c9",
          "grade": false,
          "grade_id": "cell-e2fe967b3fd6a3af",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "Now that we have created our training and test datasets, we can create dataloaders to iterate over them in batches. We will use a batch size of 64 in our experiments. Note that lower the batch size lesser will be your memory requirements but the noisier will be the training. Since in our case features are sufficiently high dimensional, we might not want to use too large of a batch size, hence we are using 64."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "6Y1Dv0inRi_o",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "f583c8e751bde8e34a1f950f8ffd9cad",
          "grade": false,
          "grade_id": "cell-129a08eb6dde4719",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "train_dataloader = DataLoader(train_dataset, batch_size = batch_size)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size = batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "BoU8QOTSXPlk",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "e432170cebdb98ea20c39e0ae65629b1",
          "grade": false,
          "grade_id": "cell-2dfd4c445918497e",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "Dataloaders work like any iterable (like Lists, dictionaries etc) in python can be iterated over using a for loop like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "deletable": false,
        "editable": false,
        "id": "mCj8wKC7XPEv",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "72ab40d81ad55f9eafa0f5d5a4986d1d",
          "grade": false,
          "grade_id": "cell-9b44a960453c0f4c",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "outputId": "7f970b99-d8ca-4fc4-ea17-a63d76780c2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features Shape: torch.Size([64, 10781])\n",
            "Labels Shape: torch.Size([64])\n"
          ]
        }
      ],
      "source": [
        "for batch in train_dataloader:\n",
        "  # Unpacking the batch\n",
        "  features, labels = batch\n",
        "  print(f\"Features Shape: {features.shape}\")\n",
        "  print(f\"Labels Shape: {labels.shape}\")\n",
        "\n",
        "  # We will break for now as this is just for demonstration\n",
        "  break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "-JOot4W8Yr8y",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "473b9b9cf17e02703cca9894209aca7f",
          "grade": false,
          "grade_id": "cell-6d795607c997ddb6",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "Notice how each batch unraps to a features and a labels torch tensor. Features is a 64x10781, where 64 is the batch size used by us and 10781 is the numeber of features we have for each document. Torch tensors behave very similar to numpy arrays, with the benifit that these can be transferred to a GPU and also support auto-differentiation. We will address these points again when we implement the training loop."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "-YwQLCrJZr8I",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "89d7219b7776d624144fdadedfc60c81",
          "grade": false,
          "grade_id": "cell-eb2d1a2cd2ce6882",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "### Task 3.2: Define the model architecture for the Logistic Regression Classifier (0.75 Marks)\n",
        "\n",
        "Pytorch provides very elegantly designed `torch.nn` module which contains building blocks for creating different neural network architectures. Some of the sub-modules included in `torch.nn` includes:\n",
        "\n",
        "- `torch.nn.Linear` : Perhaps one of the simplest of the nn modules, it is used to apply a linear transformation to the data i.e. y = xA^T +b, where x is the input and y is the output of the layer. A and b are the parameters of the layer, where A is often called the weights matrix and b is the bias vector.\n",
        "\n",
        "- `torch.nn.Conv2d`: Used to create Convolutional Layers.\n",
        "\n",
        "- `torch.nn.Transformer`: Used to create Transformer layers\n",
        "\n",
        "and many more. For the purposes of this assignment we will only be needing `torch.nn.Linear` to define our network.\n",
        "\n",
        "It also supports different activation functions like:\n",
        "- `torch.nn.ReLU` \n",
        "- `torch.nn.Sigmoid`\n",
        "- `torch.nn.Tanh`\n",
        "- `torch.nn.Softmax`\n",
        "\n",
        "\n",
        "\n",
        "Below we demonstrate the usage of some of these modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "deletable": false,
        "editable": false,
        "id": "f3TXwXWWh7hu",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "5894dbc179cce085dfba8135bebc0546",
          "grade": false,
          "grade_id": "cell-f9edd5a25c8c910c",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "outputId": "027aaf75-7410-457c-ab3c-803786903958"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: tensor([0.9309, 0.9436, 0.1037, 0.6090, 0.4499])\n",
            "Input Shape: torch.Size([5])\n",
            "Linear layer output: tensor([-0.6394, -0.1725,  0.1066], grad_fn=<AddBackward0>)\n",
            "Linear layer output Shape: torch.Size([3])\n",
            "************************************************\n",
            "\n",
            "Batched Input:\n",
            " tensor([[0.4458, 0.8991, 0.7547, 0.6292, 0.4752],\n",
            "        [0.7081, 0.4677, 0.9491, 0.7117, 0.7227],\n",
            "        [0.1337, 0.1368, 0.1758, 0.1786, 0.3972],\n",
            "        [0.2917, 0.5716, 0.3378, 0.4113, 0.1846]])\n",
            "Batched Input Shape: torch.Size([4, 5])\n",
            "Linear layer batched output:\n",
            " tensor([[-0.5429, -0.1004,  0.3649],\n",
            "        [-0.3757, -0.2013,  0.3861],\n",
            "        [-0.4094, -0.4308, -0.0376],\n",
            "        [-0.4979, -0.2010,  0.0930]], grad_fn=<AddmmBackward0>)\n",
            "Linear layer batched output Shape: torch.Size([4, 3])\n",
            "************************************************\n",
            "\n",
            "Before Applying the activation function:\n",
            " tensor([[-0.5429, -0.1004,  0.3649],\n",
            "        [-0.3757, -0.2013,  0.3861],\n",
            "        [-0.4094, -0.4308, -0.0376],\n",
            "        [-0.4979, -0.2010,  0.0930]], grad_fn=<AddmmBackward0>)\n",
            "After Applying the sigmoid function:\n",
            " tensor([[0.3675, 0.4749, 0.5902],\n",
            "        [0.4072, 0.4499, 0.5953],\n",
            "        [0.3990, 0.3939, 0.4906],\n",
            "        [0.3780, 0.4499, 0.5232]], grad_fn=<SigmoidBackward0>)\n",
            "After Applying the relu function:\n",
            " tensor([[0.0000, 0.0000, 0.3649],\n",
            "        [0.0000, 0.0000, 0.3861],\n",
            "        [0.0000, 0.0000, 0.0000],\n",
            "        [0.0000, 0.0000, 0.0930]], grad_fn=<ReluBackward0>)\n",
            "************************************************\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Create a linear layer that maps a 5 dimensional vector to a 3 dimensional vector\n",
        "example_linear_layer = nn.Linear(5, 3) # Initialize a linear layer\n",
        "example_input = torch.rand(5) # Create a random vector for demonstration\n",
        "print(f\"Input: {example_input}\")\n",
        "print(f\"Input Shape: {example_input.shape}\")\n",
        "example_output = example_linear_layer(example_input) # Feed the example input to the linear layer\n",
        "print(f\"Linear layer output: {example_output}\")\n",
        "print(f\"Linear layer output Shape: {example_output.shape}\")\n",
        "\n",
        "print(\"************************************************\\n\")\n",
        "\n",
        "# We can also use linear layers with batched inputs\n",
        "example_batch_input = torch.rand(4,5) # Create an example input containing 4 inputs of 5 dimension each\n",
        "print(f\"Batched Input:\\n {example_batch_input}\")\n",
        "print(f\"Batched Input Shape: {example_batch_input.shape}\")\n",
        "example_batch_output = example_linear_layer(example_batch_input)\n",
        "print(f\"Linear layer batched output:\\n {example_batch_output}\")\n",
        "print(f\"Linear layer batched output Shape: {example_batch_output.shape}\")\n",
        "\n",
        "print(\"************************************************\\n\")\n",
        "\n",
        "# Using activation functions\n",
        "sigmoid_activation = nn.Sigmoid() #Define sigmoid activation\n",
        "relu_activation = nn.ReLU() #Define relu activation\n",
        "\n",
        "sigmoid_output = sigmoid_activation(example_batch_output) # Apply the sigmoid function to the output of the linear layer\n",
        "relu_output = relu_activation(example_batch_output) # Apply the relu function to the output of the linear layer\n",
        "print(f\"Before Applying the activation function:\\n {example_batch_output}\")\n",
        "print(f\"After Applying the sigmoid function:\\n {sigmoid_output}\")\n",
        "print(f\"After Applying the relu function:\\n {relu_output}\")\n",
        "\n",
        "print(\"************************************************\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "K81l_ca-tPre",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "1c0ef9e9bfb4945074b9bb6d6ea6defd",
          "grade": false,
          "grade_id": "cell-7d61d873e142415c",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "Notice how the outputs of the nn layers also contain a `grad_fn`. This is used during backpropagation to compute the gradients which are used by the optimizer to learn the parameters of these layers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "WKgETCP1h6P9",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "d9c78de64fe540f353d6d7534d4f4947",
          "grade": false,
          "grade_id": "cell-8a8cb39a7e2f7b13",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "We define a network in Pytorch by extending the `torch.nn.Module` class and implementing the `__init__` and `forward` method. The `__init__` method is used to define the components of the architecture, while `forward`, takes an input tensor and passes it through the different layers of the network. You can refer to the documentation for `torch.nn` [here](https://pytorch.org/docs/stable/nn.html) and also can refer to [this](https://pytorch.org/tutorials/beginner/nn_tutorial.html) for a detailed tutorial on the same. \n",
        "\n",
        "Below we implement the `LogisticRegressionModel` class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "id": "d8asqBPFYK4m",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "561efba661865d0edb27589ed1724d4c",
          "grade": false,
          "grade_id": "cell-688fd07073adc6d3",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class LogisticRegressionModel(nn.Module):\n",
        "\n",
        "    def __init__(self, d_input):\n",
        "        \"\"\"\n",
        "        Define the architecture of a Logistic Regression classifier.\n",
        "        You will need to define two components, one will be the linear layer using\n",
        "        nn.Linear, and a sigmoid activation function for the output.\n",
        "\n",
        "        Inputs:\n",
        "          - d_input (int): The dimensionality or number of features in each input. \n",
        "                            This will be required to define the linear layer\n",
        "\n",
        "        Hint: Recall that in logistic regression we obtain a single probablility\n",
        "        value for each input that denotes how likely is the input belonging\n",
        "        to the positive class\n",
        "        \"\"\"\n",
        "        #Need to call the constructor of the parent class\n",
        "        super(LogisticRegressionModel, self).__init__()\n",
        "\n",
        "        self.linear_layer = nn.Linear(d_input,1)\n",
        "        self.sigmoid_layer = nn.Sigmoid()\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Passes the input `x` through the layers in the network and returns the output\n",
        "\n",
        "        Inputs:\n",
        "          - x (torch.tensor): A torch tensor of shape [batch_size, d_input] representing the batch of inputs\n",
        "\n",
        "        Returns:\n",
        "          - output (torch.tensor): A torch tensor of shape [batch_size,] obtained after passing the input to the network\n",
        "\n",
        "        \"\"\"\n",
        "        output = self.linear_layer(x)\n",
        "        output=self.sigmoid_layer(output)\n",
        "\n",
        "\n",
        "\n",
        "        return output.squeeze(-1) # Question: Why do squeeze() here? "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "deletable": false,
        "editable": false,
        "id": "-1qD-_S3xgn3",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "bec5fd5e0a65fc5d1a2cf43596275665",
          "grade": true,
          "grade_id": "cell-a6bd7ef76c46b9cc",
          "locked": true,
          "points": 0.75,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "outputId": "4122b256-de71-4882-d9d1-792ba70279d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Sample Test Cases\n",
            "Sample Test Case 1: Testing linear layer input and output sizes, for d_input = 5\n",
            "Number of Input Features: 5\n",
            "Number of Output Features: 1\n",
            "Expected Number of Input Features: 5\n",
            "Expected Number of Output Features: 1\n",
            "**********************************\n",
            "\n",
            "Sample Test Case 2: Testing linear layer input and output sizes, for d_input = 24\n",
            "Number of Input Features: 24\n",
            "Number of Output Features: 1\n",
            "Expected Number of Input Features: 24\n",
            "Expected Number of Output Features: 1\n",
            "**********************************\n",
            "\n",
            "Sample Test Case 3: Checking if the model gives correct output\n",
            "Model Output: 0.6298196315765381\n",
            "Expected Output: 0.6298196315765381\n",
            "**********************************\n",
            "\n",
            "Sample Test Case 4: Checking if the model gives correct output\n",
            "Model Output: [0.5503339 0.5428218 0.561816  0.51846  ]\n",
            "Expected Output: [0.5503339 0.5428218 0.561816  0.51846  ]\n",
            "**********************************\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"Running Sample Test Cases\")\n",
        "torch.manual_seed(42)\n",
        "d_input = 5\n",
        "sample_lr_model = LogisticRegressionModel(d_input = d_input)\n",
        "print(f\"Sample Test Case 1: Testing linear layer input and output sizes, for d_input = {d_input}\")\n",
        "in_features = sample_lr_model.linear_layer.in_features\n",
        "out_features = sample_lr_model.linear_layer.out_features\n",
        "\n",
        "print(f\"Number of Input Features: {in_features}\")\n",
        "print(f\"Number of Output Features: {out_features}\")\n",
        "print(f\"Expected Number of Input Features: {d_input}\")\n",
        "print(f\"Expected Number of Output Features: {1}\")\n",
        "assert in_features == d_input and out_features == 1\n",
        "\n",
        "print(\"**********************************\\n\")\n",
        "d_input = 24\n",
        "sample_lr_model = LogisticRegressionModel(d_input = d_input)\n",
        "print(f\"Sample Test Case 2: Testing linear layer input and output sizes, for d_input = {d_input}\")\n",
        "in_features = sample_lr_model.linear_layer.in_features\n",
        "out_features = sample_lr_model.linear_layer.out_features\n",
        "\n",
        "print(f\"Number of Input Features: {in_features}\")\n",
        "print(f\"Number of Output Features: {out_features}\")\n",
        "print(f\"Expected Number of Input Features: {d_input}\")\n",
        "print(f\"Expected Number of Output Features: {1}\")\n",
        "assert in_features == d_input and out_features == 1\n",
        "print(\"**********************************\\n\")\n",
        "\n",
        "print(f\"Sample Test Case 3: Checking if the model gives correct output\")\n",
        "test_input = torch.rand(d_input)\n",
        "model_output = sample_lr_model(test_input)\n",
        "model_output_np = model_output.detach().numpy()\n",
        "expected_output = 0.6298196315765381\n",
        "print(f\"Model Output: {model_output_np}\")\n",
        "print(f\"Expected Output: {expected_output}\")\n",
        "\n",
        "assert np.allclose(model_output_np, expected_output, 1e-5)\n",
        "print(\"**********************************\\n\")\n",
        "\n",
        "print(f\"Sample Test Case 4: Checking if the model gives correct output\")\n",
        "test_input = torch.rand(4, d_input)\n",
        "model_output = sample_lr_model(test_input)\n",
        "model_output_np = model_output.detach().numpy()\n",
        "expected_output = np.array([0.5503339, 0.5428218, 0.561816,  0.51846  ])\n",
        "print(f\"Model Output: {model_output_np}\")\n",
        "print(f\"Expected Output: {expected_output}\")\n",
        "\n",
        "assert model_output_np.shape == expected_output.shape and np.allclose(model_output_np, expected_output, 1e-5)\n",
        "print(\"**********************************\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "W2tQHcs36Ec5",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "7835e7f98da057f95fbfaadf1da2f23f",
          "grade": false,
          "grade_id": "cell-099f26bffc5c1d0a",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "Now that our logistic regression model seems to be defined correctly, let's initialize the model for our sentiment task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "deletable": false,
        "editable": false,
        "id": "GzInqWf46Dpo",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "d145bd7f9a4928bae997a9644f62f19c",
          "grade": false,
          "grade_id": "cell-58464221477c485c",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "outputId": "17d2f632-6ac9-46e8-c59e-4fc7a5431f96"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegressionModel(\n",
              "  (linear_layer): Linear(in_features=10781, out_features=1, bias=True)\n",
              "  (sigmoid_layer): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "sentiment_lr_model = LogisticRegressionModel(\n",
        "    d_input = len(train_vocab)\n",
        ")\n",
        "sentiment_lr_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "e1ZSvNsI6fm4",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "3c106575de62338c3aac13f3c81b06de",
          "grade": false,
          "grade_id": "cell-2629df60b2e8e2d6",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "### Defining a loss function\n",
        "\n",
        "Now that we have implemented the model architecture, to train it we first need to define a loss function which we will minimize using an optimization algorithm. A loss function meausres how well the predictions of the model alligns with the actual training labels. In addition to the architecture blocks and activation functions `torch.nn` also offers a wide variety of loss functions that include:\n",
        "- `torch.nn.MSELoss` : Mean squared error loss function. Typically used for regression problems.\n",
        "- `torch.nn.L1Loss`: Mean absolute error loss function. Like MSE loss it is also used for regression problems. Takes the mean of absolute value of the errors instead of squared values.\n",
        "- `torch.nn.BCELoss`: Binary Cross Entropy loss function. It is used in binary classification problems i.e. the classification problems where there are only 2 possible labels (positive and negative), like in our case.\n",
        "- `torch.nn.CrossEntropyLoss`: Cross Entropy loss function. Similar to BCELoss but works for multi-class classification problems as well.\n",
        "\n",
        "You can look at the documentations of these and multiple other loss functions included in `torch.nn` package [here](https://pytorch.org/docs/stable/nn.html#loss-functions). For our purposes since we will be using `torch.nn.BCELoss`. Below we define the loss function and demonstrate the usage on an example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cN4I98QC8zop",
        "outputId": "ec097f27-17d2-41ca-fa8f-b48cc300cf84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.8614, grad_fn=<BinaryCrossEntropyBackward0>)\n"
          ]
        }
      ],
      "source": [
        "loss_fn = nn.BCELoss()\n",
        "\n",
        "# Demonstarting usage on a random example\n",
        "torch.manual_seed(42)\n",
        "example_model = LogisticRegressionModel(d_input = 5)\n",
        "input = torch.rand(2, 5) # Defining a random input for demonstration\n",
        "preds = example_model(input)\n",
        "labels = torch.FloatTensor([1,0]) # Defining a random labels for demonstration\n",
        "loss = loss_fn(preds, labels)\n",
        "print(loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "Un0L_x_L3FxT",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "286345cd8866563f70a9aa2471ab1bf4",
          "grade": false,
          "grade_id": "cell-f979921b070274f7",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "As you can see the `loss_fn` takes as the input the prediction probabilities on a batch of inputs which are typically obtained by applying a sigmoid function to the output, and the labels corresponding to the each input. Again note that the loss also contains a `grad_fn`. We can use `loss.backward()` to compute the gradients with respect to all the model parameters "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDBPzQ2_3FGR",
        "outputId": "55d735f6-a2e5-4da5-8331-f33daa361128"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "tensor([[ 0.1525,  0.1364,  0.0011,  0.2294, -0.0456]])\n"
          ]
        }
      ],
      "source": [
        "print(example_model.linear_layer.weight.grad)\n",
        "loss.backward()\n",
        "print(example_model.linear_layer.weight.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "TXvSg01QCHqj",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "bed05ba574ac8f011eb0845adce43a71",
          "grade": false,
          "grade_id": "cell-3632ecc34cfdee23",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "Notice how before calling `loss.backward()` the gradient was None, but after the call it gets populated. The gradients will then be used by the optimizer to update the parameters, which is a nice segway to our next topic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "kczo95DjC3AB",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "d8ef8b3afd4eb559177901a26a9b4207",
          "grade": false,
          "grade_id": "cell-01b8e849ec0cbea1",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "### Defining an Optimizer\n",
        "\n",
        "An optimizer is used to find the optimum set of parameters of the model that minimize the loss functions. Most commonly used optimizers in Machine Learning, especially in Deep Learning are the variants of Stochastic Gradient Descent (SGD), which updates the parameters of the model by moving then in the opposite direction of the gradients.\n",
        "\n",
        "![1406-7.png](data:image/png;base64,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)\n",
        "\n",
        "\n",
        "Here, Θ denotes the model parameters, J is the loss function and α is what we call learning rate which is used to specify the strength of the step that we wish to take. A smaller learning rate ensures we do not move away from the minima, but it makes the learning slower, while with a larger learning rate we move quickly towards the minima but are susceptible to overshooting it. Variants of SGD like SGD + Momentum, RMSProp, Adam etc., tries to improve it's noisy nature (which arises due to the fact we work on batches, instead of the entire dataset at a time), by introducing minor modifications to the update equation to prevent the optimizer taking a step in an overly wrong direction, and some also introduce heuristics to decay the step size as we reach closer to the minima. Adam is one of the most used optimizers in Deep Learning applications and often works reasonably well in practical applications. We will use the same for our experiments. You can read more about how these different optimizers work [here](https://cs231n.github.io/neural-networks-3/). \n",
        "\n",
        "`torch.optim` provides implementations for all of the optimizers we mentioned above. For official documentation for the same, refer [here](For officialy)/ Below we provide an example on how to define and use optimizers in pytorch\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R3Bjhr47CCeK"
      },
      "outputs": [],
      "source": [
        "from torch.optim import Adam\n",
        "\n",
        "torch.manual_seed(42)\n",
        "# We will first need to define the model\n",
        "example_model = LogisticRegressionModel(d_input = 5)\n",
        "\n",
        "# Defining the optimizer\n",
        "example_optim = Adam(example_model.parameters(), lr = 1e-3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "SGgdODqGIoWq",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "50855aecff119f81e43b3df0c4a2d4c8",
          "grade": false,
          "grade_id": "cell-3a5a88369ea13542",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "Notice that the optimizer takes as input two arguments, the first is the parameters (Θ) of the model that are to be learned using the optimizer and the second is the learning rate (α). Adam optimizer also has other hyperparameters like β1 , β2, ϵ, details of which are beyond the scope of this assignment. However, you need not worry about setting these hyper-parameters as in most of the cases the default vaues of these work well enough. Next let's see how to update the model's parameters using the optimizer\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLNlnpgsB82x",
        "outputId": "462643a5-d1d3-4f4f-95a1-094d7eb575ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameters before the update: Parameter containing:\n",
            "tensor([[ 0.3419,  0.3712, -0.1048,  0.4108, -0.0980]], requires_grad=True)\n",
            "Parameters after the update: Parameter containing:\n",
            "tensor([[ 0.3409,  0.3702, -0.1058,  0.4098, -0.0970]], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "example_optim.zero_grad() # This is done to zero-out any existing gradients stored from some previous steps\n",
        "input = torch.rand(2, 5) # Defining a random input for demonstration\n",
        "preds = example_model(input)\n",
        "labels = torch.FloatTensor([1,0]) # Defining a random labels for demonstration\n",
        "loss = loss_fn(preds, labels)\n",
        "loss.backward() # Perform backward pass\n",
        "print(f\"Parameters before the update: {example_model.linear_layer.weight}\")\n",
        "example_optim.step() # Update the parameters using the optimizer\n",
        "print(f\"Parameters after the update: {example_model.linear_layer.weight}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "cc8E918pOsq0",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "d05588bcefb43ddbc27b0cc64853505d",
          "grade": false,
          "grade_id": "cell-e75eef4c28c7203d",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "As you can see after calling `example_optim.step()` the parameters get updated. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "7f2Fdb2ZU1ei",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "e392158da462c9d19b8304dfa5917564",
          "grade": false,
          "grade_id": "cell-6e77847e377e083a",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "### Task 3.3: Training the Model (2.25 Marks)\n",
        "\n",
        "Now we have all the different components ready and can start training our sentiment classifier. Implement the `train` function below\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "id": "lEgvxQhBOq4u",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "ac63b3bf97ebaaf39d8159c2d4846576",
          "grade": true,
          "grade_id": "cell-bda0b7948d888555",
          "locked": false,
          "points": 2.25,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import Adam\n",
        "\n",
        "def train(model, train_dataloader,\n",
        "          lr = 1e-3, num_epochs = 20,\n",
        "          device = \"cuda\",):\n",
        "\n",
        "    \"\"\"\n",
        "    Runs the training loop\n",
        "\n",
        "    Inputs:\n",
        "    - model (LogisticRegressionModel): Logistic Regression model to be trained\n",
        "    - train_dataloader (torch.utils.DataLoader): A dataloader defined over the training dataset\n",
        "    - lr (float): The learning rate for the optimizer\n",
        "    - num_epochs (int): Number of epochs to train the model for.\n",
        "    - device (str): Device to train the model on. Can be either 'cuda' (for using gpu) or 'cpu'\n",
        "\n",
        "    Returns:\n",
        "    - model (LogisticRegressionModel): Model after completing the training\n",
        "    - epoch_loss (float) : Loss value corresponding to the final epoch\n",
        "    \"\"\"\n",
        "\n",
        "    # Transfer the model to specified device\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Step 1: Define the Binary Cross Entropy loss function\n",
        "    loss_fn = nn.BCELoss()\n",
        "  \n",
        "    # Step 2: Define Adam Optimizer\n",
        "    optimizer = Adam(model.parameters(),lr=lr)\n",
        "\n",
        "\n",
        "    # Iterate over `num_epochs`\n",
        "    for epoch in range(num_epochs):\n",
        "        epoch_loss = 0 # We can use this to keep track of how the loss value changes as we train the model.\n",
        "        # Iterate over each batch using the `train_dataloader`\n",
        "        for train_batch in tqdm.tqdm(train_dataloader):\n",
        "            # Zero out any gradients stored in the previous steps\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Unwrap the batch to get features and labels\n",
        "            features, labels = train_batch\n",
        "\n",
        "            # Most nn modules and loss functions assume the inputs are of type Float, so convert both features and labels to floats\n",
        "            features = features.float()\n",
        "            labels = labels.float()\n",
        "\n",
        "            # Transfer the features and labels to device\n",
        "            features = features.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "\n",
        "            # Step 3: Feed the input features to the model to get predictions\n",
        "            preds = model(features)\n",
        "            # Step 4: Compute the loss and perform backward pass\n",
        "            loss = loss_fn(preds,labels)\n",
        "            loss.backward()\n",
        "\n",
        "            # Step 5: Take optimizer step\n",
        "            optimizer.step()\n",
        "            # Store loss value for tracking\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "        epoch_loss = epoch_loss / len(train_dataloader)\n",
        "        print(f\"Epoch {epoch} completed.. Average Loss: {epoch_loss}\")\n",
        "\n",
        "    return model, epoch_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "deletable": false,
        "editable": false,
        "id": "_H4_v07ViC50",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "16062350acd2066029a73ce93b176e0a",
          "grade": true,
          "grade_id": "cell-62f537900cbf53d1",
          "locked": true,
          "points": 0,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "outputId": "5a2e6b69-d69c-4480-d5f1-ff696b234b8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Sample Test Cases\n",
            "Training on just 100 training examples for sanity check\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 592.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 completed.. Average Loss: 0.6931628614664078\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 595.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 completed.. Average Loss: 0.5336113433539867\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 567.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 completed.. Average Loss: 0.4253938866406679\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 568.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 completed.. Average Loss: 0.35027071021497247\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 579.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 completed.. Average Loss: 0.295130567997694\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 575.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 completed.. Average Loss: 0.25295863080769776\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 567.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 completed.. Average Loss: 0.21972406229004263\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 572.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 completed.. Average Loss: 0.19292184961959719\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 528.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 completed.. Average Loss: 0.1709036991558969\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 562.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 completed.. Average Loss: 0.1525375072658062\n",
            "Final Loss Value: 0.1525375072658062\n",
            "Expected Loss Value: 0.1525375072658062\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"Running Sample Test Cases\")\n",
        "\n",
        "print(\"Training on just 100 training examples for sanity check\")\n",
        "torch.manual_seed(42)\n",
        "sample_documents = train_df_preprocessed[\"sentence\"].values.tolist()[:100]\n",
        "sample_labels = train_df[\"label\"].values.tolist()[:100]\n",
        "sample_vocab = create_vocab(train_documents)\n",
        "sample_word2idx = get_word_idx_mapping(train_vocab)\n",
        "\n",
        "sample_dataset = SST2Dataset(sample_documents,\n",
        "                            sample_labels,\n",
        "                            sample_vocab,\n",
        "                            sample_word2idx)\n",
        "\n",
        "sample_dataloader = DataLoader(sample_dataset)\n",
        "\n",
        "sample_lr_model = LogisticRegressionModel(d_input = len(sample_vocab))\n",
        "\n",
        "sample_lr_model, loss = train(sample_lr_model, sample_dataloader,lr = 1e-2, num_epochs = 10,device = \"cuda\")\n",
        "\n",
        "expected_loss = 0.1525375072658062\n",
        "print(f\"Final Loss Value: {loss}\")\n",
        "print(f\"Expected Loss Value: {expected_loss}\")\n",
        "\n",
        "#assert np.allclose(expected_loss, loss, 1e-3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "c_ssqj6MhwXJ",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "2a4c8f5ae9dfbb9b441684be8b517298",
          "grade": false,
          "grade_id": "cell-b142da2242674d80",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "Don't worry if the exact loss values do not match, as long as your loss is reducing with epochs and the final loss is in the same range, you should be fine. And now lets train on the entire dataset, this may take some time, approximate 4 minutes per epoch. So relax and have yourself a cup of coffee while this runs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "deletable": false,
        "editable": false,
        "id": "FGLFCmFkzyqc",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "3cbc3ecad9884fbc8cf7875e8030df5f",
          "grade": false,
          "grade_id": "cell-ca17de4d581b63da",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "outputId": "e271a198-6408-44d2-906b-124d4acb737c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1053/1053 [00:14<00:00, 72.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 completed.. Average Loss: 0.4330625123815772\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1053/1053 [00:14<00:00, 71.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 completed.. Average Loss: 0.29772520692203575\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1053/1053 [00:15<00:00, 69.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 completed.. Average Loss: 0.2561558991430039\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1053/1053 [00:14<00:00, 72.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 completed.. Average Loss: 0.23294667907391745\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1053/1053 [00:14<00:00, 72.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 completed.. Average Loss: 0.21770785217582897\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "sentiment_lr_model = LogisticRegressionModel(\n",
        "    d_input = len(train_vocab)\n",
        ")\n",
        "sentiment_lr_model, final_loss = train(sentiment_lr_model, train_dataloader,\n",
        "      lr = 1e-2, num_epochs = 5,\n",
        "      device = device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "wZXvrhEmolLq",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "f1105dec2084f36e71aa7c0057bb7265",
          "grade": false,
          "grade_id": "cell-d29b6970919f9dd7",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "### Task 3.4: Evaluating the Model (1.25 Marks)\n",
        "\n",
        "Evaluation is one of the most important step in a Machine Learning pipeline, as it help us measure how well the trained is able to predict on unseen data. There are different performance metrics that can be used for evaluating machine learning algorithms. One of the most commonly used metrics for evaluating classification models is accuracy which is defined as the number of test examples predicted correctly by the model divided by the total number of test examples.![1_udGMH6OQF4CMcv42mjW_qg.png](data:image/png;base64,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)\n",
        "\n",
        "To check the number of correct predictions we can check the label predicted by our model and the actual label for a test example and if they both are the same. However, note that our model outputs probabilities and not the labals 0 or 1. One common practice to convert probabilities to predictions is to define a threshold ϵ (typically kept at 0.5) and if the predicted probability is > ϵ then assign the example a positive label i.e. 1 and else 0. We start by implementing `convert_probs_to_labels` function which does exactly that"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "id": "nAWTto1bBBu_",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "511e99d18670a1420965175d364fde52",
          "grade": false,
          "grade_id": "cell-7ab99bc2c084b78d",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "def convert_probs_to_labels(probs, threshold = 0.5):\n",
        "  \"\"\"\n",
        "  Convert the probabilities to labels by using the specified threshold\n",
        "\n",
        "  Inputs:\n",
        "    - probs (numpy.ndarray): A numpy 1d array containing the probabilities predicted by the classifier model\n",
        "    - threshold (float): A threshold value beyond which we assign a positive label i.e 1 and 0 below it\n",
        "\n",
        "  Returns:\n",
        "    - labels (numpy.ndarray): Labels obtained after thresholding\n",
        "    \n",
        "  \"\"\"\n",
        "    \n",
        "  labels =[]\n",
        "  for value in probs:\n",
        "    if value>threshold:\n",
        "      labels.append(1)\n",
        "    else:\n",
        "      labels.append(0)\n",
        "\n",
        "  return labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "deletable": false,
        "editable": false,
        "id": "WUD3S4P1s7Zc",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "1ec0ba192d8c2bf2d6829ca673c32bcb",
          "grade": true,
          "grade_id": "cell-4a01d59eb7100f8e",
          "locked": true,
          "points": 0.25,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "outputId": "853ca69d-0471-419b-8759-dc8d7b78ec97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Sample Test Cases\n",
            "Sample Test Case 1\n",
            "Input Probabilities: [0.1  0.45 0.65 0.9  0.55]\n",
            "Input Threshold: 0.5\n",
            "Lables: [0, 0, 1, 1, 1]\n",
            "Expected Lables: [0 0 1 1 1]\n",
            "**********************************\n",
            "\n",
            "Sample Test Case 2\n",
            "Input Probabilities: [0.1  0.45 0.65 0.9  0.55]\n",
            "Input Threshold: 0.75\n",
            "Lables: [0, 0, 0, 1, 0]\n",
            "Expected Lables: [0 0 0 1 0]\n",
            "**********************************\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"Running Sample Test Cases\")\n",
        "\n",
        "print(\"Sample Test Case 1\")\n",
        "sample_probs = np.array([0.1, 0.45, 0.65, 0.9, 0.55])\n",
        "sample_threshold = 0.5\n",
        "print(f\"Input Probabilities: {sample_probs}\")\n",
        "print(f\"Input Threshold: {sample_threshold}\")\n",
        "sample_labels = convert_probs_to_labels(sample_probs, sample_threshold)\n",
        "expected_labels = np.array([0, 0, 1, 1, 1])\n",
        "print(f\"Lables: {sample_labels}\")\n",
        "print(f\"Expected Lables: {expected_labels}\")\n",
        "\n",
        "assert (sample_labels == expected_labels).all()\n",
        "print(\"**********************************\\n\")\n",
        "\n",
        "print(\"Sample Test Case 2\")\n",
        "sample_probs = np.array([0.1, 0.45, 0.65, 0.9, 0.55])\n",
        "sample_threshold = 0.75\n",
        "print(f\"Input Probabilities: {sample_probs}\")\n",
        "print(f\"Input Threshold: {sample_threshold}\")\n",
        "sample_labels = convert_probs_to_labels(sample_probs, sample_threshold)\n",
        "expected_labels = np.array([0, 0, 0, 1, 0])\n",
        "print(f\"Lables: {sample_labels}\")\n",
        "print(f\"Expected Lables: {expected_labels}\")\n",
        "\n",
        "assert (sample_labels == expected_labels).all()\n",
        "print(\"**********************************\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "xOlABIEHvRnB",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "3357a47a0d11bb9144749958aab6e0bb",
          "grade": false,
          "grade_id": "cell-f49f4043d76742d7",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "Next lets implement the `get_accuracy` function which takes as input predicted labels and actual labels and computes the accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "id": "Y1VhwC5WvYxr",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "58a3dc81c8ff49c4934c7ff8112b064a",
          "grade": false,
          "grade_id": "cell-ed9814cc82b4b4dd",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "def get_accuracy(pred_labels, act_labels):\n",
        "  \"\"\"\n",
        "  Calculates the accuracy value by comparing predicted labels with actual labels\n",
        "\n",
        "  Inputs:\n",
        "    - pred_labels (numpy.ndarray) : A numpy 1d array containing predicted labels. \n",
        "    - act_labels (numpy.ndarray): A numpy 1d array containing actual labels (of same size as pred_labels). \n",
        "\n",
        "  Returns:\n",
        "    - accuracy (float): Number of correct predictions / Total number of predictions\n",
        "\n",
        "  \"\"\"\n",
        "  accuracy = None\n",
        "  correct_predictions=0\n",
        "  for prediction,actual in zip(pred_labels,act_labels):\n",
        "    if prediction==actual:\n",
        "      correct_predictions+=1\n",
        "  accuracy=correct_predictions/len(pred_labels)\n",
        "\n",
        "  return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "deletable": false,
        "editable": false,
        "id": "ShWo6Kl0wfne",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "71ce19a6302a52b34c368bfa4d72df19",
          "grade": true,
          "grade_id": "cell-21d679aad70d9602",
          "locked": true,
          "points": 0.5,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "outputId": "8f190794-1133-4c0b-91d2-c6daa55f0b38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Sample Test Cases\n",
            "Sample Test Case 1\n",
            "Input Predicted Labels: [0 0 1 1]\n",
            "Input Actual Labels: [0 0 0 1]\n",
            "Accuracy: 0.75\n",
            "Expected Accuracy: 0.75\n",
            "**********************************\n",
            "\n",
            "Sample Test Case 2\n",
            "Input Predicted Labels: [0 0 1 1 0]\n",
            "Input Actual Labels: [1 1 0 0 1]\n",
            "Accuracy: 0.0\n",
            "Expected Accuracy: 0\n",
            "**********************************\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"Running Sample Test Cases\")\n",
        "\n",
        "print(\"Sample Test Case 1\")\n",
        "sample_pred_labels = np.array([0, 0, 1, 1])\n",
        "sample_act_labels = np.array([0, 0, 0, 1])\n",
        "sample_acc = get_accuracy(sample_pred_labels, sample_act_labels)\n",
        "expected_acc = 0.75\n",
        "print(f\"Input Predicted Labels: {sample_pred_labels}\")\n",
        "print(f\"Input Actual Labels: {sample_act_labels}\")\n",
        "print(f\"Accuracy: {sample_acc}\")\n",
        "print(f\"Expected Accuracy: {expected_acc}\")\n",
        "\n",
        "assert sample_acc == expected_acc\n",
        "print(\"**********************************\\n\")\n",
        "\n",
        "print(\"Sample Test Case 2\")\n",
        "sample_pred_labels = np.array([0, 0, 1, 1, 0])\n",
        "sample_act_labels = np.array([1, 1, 0, 0, 1])\n",
        "sample_acc = get_accuracy(sample_pred_labels, sample_act_labels)\n",
        "expected_acc = 0\n",
        "print(f\"Input Predicted Labels: {sample_pred_labels}\")\n",
        "print(f\"Input Actual Labels: {sample_act_labels}\")\n",
        "print(f\"Accuracy: {sample_acc}\")\n",
        "print(f\"Expected Accuracy: {expected_acc}\")\n",
        "\n",
        "assert sample_acc == expected_acc\n",
        "\n",
        "print(\"**********************************\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "V_iKfN8WxkH8",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "e00f161db470bca27d0538b7c6124b58",
          "grade": false,
          "grade_id": "cell-f73ba4d7f000e6bb",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "Now we can implement `evaluate` function which takes in a model and a test dataloader, iterates through every batch of the test dataset and calculates the average accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "id": "Yac4aNBHxKjP",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "eef1905a763f632a98cf9caeecd5719a",
          "grade": true,
          "grade_id": "cell-80252e20034d4918",
          "locked": false,
          "points": 0.5,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "def evaluate(model, test_dataloader, threshold = 0.5, device = \"cuda\"):\n",
        "  \"\"\"\n",
        "  Evaluates `model` on test dataset\n",
        "\n",
        "  Inputs:\n",
        "    - model (LogisticRegressionModel): Logistic Regression model to be evaluated\n",
        "    - test_dataloader (torch.utils.DataLoader): A dataloader defined over the test dataset\n",
        "\n",
        "  Returns:\n",
        "    - accuracy (float): Average accuracy over the test dataset \n",
        "  \"\"\"\n",
        "  model.to(device)\n",
        "  model = model.eval() # Set model to evaluation model \n",
        "  accuracy = 0\n",
        "  \n",
        "  # by specifying `torch.no_grad`, it ensures no gradients are calcuated while running the model,\n",
        "  # this makes the computation much more faster\n",
        "  with torch.no_grad():\n",
        "    for test_batch in test_dataloader:\n",
        "      features, labels = test_batch\n",
        "      features = features.float().to(device)\n",
        "      labels = labels.float().to(device)\n",
        "\n",
        "      # Step 1: Get probability predictions from the model and store it in `pred_probs`\n",
        "      pred_probs = model(features)\n",
        "\n",
        "      # Convert predictions and labels to numpy arrays from torch tensors as they are easier to operate for computing metrics\n",
        "      pred_probs = pred_probs.detach().cpu().numpy()\n",
        "      labels = labels.detach().cpu().numpy()\n",
        "\n",
        "      # Step 2: Get accuracy of predictions and store it in `batch_accuracy`\n",
        "      predictions = convert_probs_to_labels(pred_probs, threshold = 0.5)\n",
        "      batch_accuracy = get_accuracy(predictions , labels)\n",
        "    \n",
        "\n",
        "      accuracy += batch_accuracy\n",
        "\n",
        "    # Divide by number of batches to get average accuracy\n",
        "    accuracy = accuracy / len(test_dataloader)\n",
        "\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_documents"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xARc0ioGJRvB",
        "outputId": "655cffdf-81ad-4d29-c8ee-94c5641f026f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['charm often affect journey',\n",
              " 'unflinchingli bleak desper',\n",
              " 'allow us hope nolan pois embark major career commerci yet invent filmmak',\n",
              " 'act costum music cinematographi sound astound given product auster local',\n",
              " 'slow slow',\n",
              " 'although lace humor fanci touch film refreshingli seriou look young women',\n",
              " 'sometim tediou film',\n",
              " 'last year tax exwif',\n",
              " 'nt know music appreci film easygo blend comedi romanc',\n",
              " 'exactli 89 minut pass slowli sit nake igloo formula 51 sank quirki jerki utter turkey',\n",
              " 'mesmer perform lead keep film ground keep audienc rivet',\n",
              " 'take strang kind lazi wast talent robert forster ann meara eugen levi reginald veljohnson movi',\n",
              " 'film suffer lack humor someth need balanc violenc',\n",
              " 'root clara paul even like though perhap emot closer piti',\n",
              " 'even horror fan like find seek troubl everi day movi lack thrill humor',\n",
              " 'gorgeou highspirit music india exquisit blend music danc song high drama',\n",
              " 'emot raw strike nerv anyon ever famili trauma',\n",
              " 'audrey tatou knack pick role magnifi outrag charm liter french comedi morningglori exuber améli',\n",
              " 'movi plain old monster',\n",
              " 'best moment resembl bad high school product greas without benefit song',\n",
              " 'pumpkin take admir look hypocrisi polit correct uneven tone never know humor end tragedi begin',\n",
              " 'iditarod last day felt like',\n",
              " 'holden caulfield better',\n",
              " 'delect intrigu thriller fill surpris read lip origin',\n",
              " 'seldom movi close match spirit man work',\n",
              " 'nick seemingli uncertain go make peopl laugh run gamut stale parodi raunchi sex gag formula romant comedi',\n",
              " 'action switch past present materi link tenuou anchor emot connect purport span 125year divid',\n",
              " 'offbeat treat poke fun democrat exercis also examin signific take part',\n",
              " 'cookiecutt movi cutandpast job',\n",
              " 'look away god aw',\n",
              " 'thank scott charismat roger eisenberg sweet nephew roger dodger one compel variat compani men',\n",
              " 'design provid mix smile tear crossroad instead provok hand unintent howler numer yawn',\n",
              " 'gorgeou witti seduct movi',\n",
              " 'movi succe instil wari sens grace god far selfconsci draw deepli world',\n",
              " 'nt believ sens humor plain bore',\n",
              " 'sequenc ridicul shoot em scene',\n",
              " 'weight piec uner profession chilli product fascin embed lurid topic prove recommend enough',\n",
              " 'w hile long amiabl monkey worthi environment jane goodal wild chimpanze short thrill overs medium demand',\n",
              " 'surreal dream detail photograph visual dexter time imagin overwhelm',\n",
              " 'escap studio piccoli warmli affect adroitli minimalist movi',\n",
              " 'tremend energi cast sens play excit seem appropri',\n",
              " 'illumin documentari transcend preconceiv vision holi land inhabit reveal human complex beneath',\n",
              " 'subtl strength ell never lose touch realiti grim situat',\n",
              " 'holm embodi charact effortlessli regal charisma',\n",
              " 'titl describ main charact lazi peopl behind camera well',\n",
              " 'offer littl beyond momentari joy pretti weightless intellectu entertain',\n",
              " 'synthesi clich absurd seem posit decad cinemat flash empti',\n",
              " 'subtl wellcraft part chiller',\n",
              " 'lot virtu eastwood best',\n",
              " 'hamper lifetimechannel kind plot lead actress depth',\n",
              " 'feel like afterschool special gussi fanci special effect watch rote plot point connect excit gaze egg timer 93 minut',\n",
              " 'part director annesophi birot first featur sensit extraordinarili wellact drama',\n",
              " 'mr tsai origin artist medium time',\n",
              " 'sade engag look controversi eponym fierc atheist hero',\n",
              " 'devoid kind intellig stori make film like xxx collater damag seem like thought treatis',\n",
              " 'tender heartfelt famili drama',\n",
              " 'hollow joke told cinemat gymnast much fun embellish misanthrop tale actual engag',\n",
              " 'cold turkey would far better titl',\n",
              " 'manag repuls sadist mundan',\n",
              " 'disappointingli superfici movi element necessari fascin involv charact studi never scratch surfac',\n",
              " 'stori two misfit nt stand chanc alon togeth magnific',\n",
              " 'schaeffer find hook hang persist useless movi might well resuscit middleag charact',\n",
              " 'primit forc film seem bubbl vast collect memori combat',\n",
              " 'tricki topic tadpol much step right direct blend frank civil compass',\n",
              " 'script kick mr hartley distend pace footdrag rhythm follow',\n",
              " 'wonder enough nt music video rather fulllength movi',\n",
              " 'hard raunchi colleg humor ticket right',\n",
              " 'fast funni highli enjoy movi',\n",
              " 'good oldfashion slashandhack back',\n",
              " 'one definit one skip even horror movi fanat',\n",
              " 'impress craftsmanship despit overbear seri thirdact crescendo lili chouchou never realli build head emot steam',\n",
              " 'exquisit nuanc mood tic dialogu chamber drama superbl act deepli appeal veteran bouquet chill quit human berl',\n",
              " 'use high comedi evok surpris poignanc',\n",
              " 'one creepiest scariest movi come along long long time easili rival blair witch other',\n",
              " 'string rehash sight gag base insipid vulgar',\n",
              " 'among year intrigu explor alient',\n",
              " 'movi fail live sum part',\n",
              " 'son room triumph gentil earn moment patho',\n",
              " 'noth outstand film good enough like appreci sailor folk know way around submarin',\n",
              " 'train wreck action film stupefi attempt filmmak forcefe jame bond mindless xxx mold throw 40 year cinemat histori toilet favor bright flash loud bang',\n",
              " 'draw big bad love solid perform arliss howard',\n",
              " 'green might want hang onto ski mask robberi may way pay next project',\n",
              " 'one pussyass world even killerthril revolv around group therapi session',\n",
              " 'though becom almost redund say major kudo go leigh actual cast peopl look workingclass',\n",
              " 'band courag face offici repress inspir especi age hippi one includ',\n",
              " 'movi achiev great impact keep thought hidden quill show',\n",
              " 'film flat line peak miss opportun trifl dark decad truffl',\n",
              " 'jaglom put audienc privileg posit eavesdrop charact',\n",
              " 'fresnadillo dark jolt imag way pli subconsci like nightmar week ago wo nt go away',\n",
              " 'know plot littl crazi held interest start finish',\n",
              " 'scattershot affair hit mark brilliant',\n",
              " 'hardli masterpiec introduc viewer good charit enterpris interest real peopl',\n",
              " 'wo nt like roger quickli recogn',\n",
              " 'steven soderbergh solari failur gloriou failur',\n",
              " 'byler reveal charact way intrigu even fascin us never reduc situat simpl melodrama',\n",
              " 'rivet world war ii moral suspens stori deal shadow side american cultur racial prejudic ugli divers form',\n",
              " 'difficult imagin process produc script guess spray chees underarm nois play crucial role',\n",
              " 'sophomor slump director sam mend segu oscar winner oscarwin potenti smooth sleight hand',\n",
              " 'whole movi lack wit feel believ compens incess coars banal',\n",
              " 'make documentari margin histor figur']"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Gw2UzGuhNvSk",
        "outputId": "644ba472-d6f4-4f73-adfd-772dce44d7a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-fb026419-8e85-41fd-bd6d-01b8f2abcebd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>it 's a charming and often affecting journey .</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>unflinchingly bleak and desperate</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>allows us to hope that nolan is poised to emba...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>the acting , costumes , music , cinematography...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>it 's slow -- very , very slow .</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fb026419-8e85-41fd-bd6d-01b8f2abcebd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fb026419-8e85-41fd-bd6d-01b8f2abcebd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fb026419-8e85-41fd-bd6d-01b8f2abcebd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                            sentence  label\n",
              "0    it 's a charming and often affecting journey .       1\n",
              "1                 unflinchingly bleak and desperate       0\n",
              "2  allows us to hope that nolan is poised to emba...      1\n",
              "3  the acting , costumes , music , cinematography...      1\n",
              "4                  it 's slow -- very , very slow .       0"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "deletable": false,
        "editable": false,
        "id": "sY8H0Rmg0sbB",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "5004bbfbb93e80b9f6abf6f1a726f94d",
          "grade": true,
          "grade_id": "cell-73575615ae8bab92",
          "locked": true,
          "points": 0,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "outputId": "c1108f92-7e53-40cd-8d5d-d0c7bca1d050"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Sample Test Cases\n",
            "Testing on just 100 test examples for sanity check\n",
            "Accuracy: 0.8090277777777778\n",
            "Expected Accuracy: 0.8090277777777778\n"
          ]
        }
      ],
      "source": [
        "print(\"Running Sample Test Cases\")\n",
        "\n",
        "print(\"Testing on just 100 test examples for sanity check\")\n",
        "torch.manual_seed(42)\n",
        "sample_documents = test_df_preprocessed[\"sentence\"].values.tolist()[:100]\n",
        "sample_labels = test_df[\"label\"].values.tolist()[:100]\n",
        "\n",
        "sample_dataset = SST2Dataset(sample_documents,\n",
        "                            sample_labels,\n",
        "                            train_vocab,\n",
        "                            train_word2idx)\n",
        "\n",
        "sample_dataloader = DataLoader(sample_dataset, batch_size = 64)\n",
        "\n",
        "accuracy = evaluate(sentiment_lr_model, sample_dataloader, device =\"cpu\")\n",
        "\n",
        "expected_accuracy = 0.8090277777777778\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Expected Accuracy: {expected_accuracy}\")\n",
        "\n",
        "#assert np.allclose(expected_accuracy, accuracy, 1e-5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvWoY_R44Zm0"
      },
      "source": [
        "Again, don't worry if the values do not match exactly. As long as the value you obtained is close to 0.8 it should be fine"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "DD4YSQ_pFNo9",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "aa6271635f57179d5c792ec32733eec0",
          "grade": false,
          "grade_id": "cell-6fef0bb78fcce993",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "Let's obtain the accuracy on the entire test set now"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "deletable": false,
        "editable": false,
        "id": "PvkP6uV9FM0f",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "1536a4a016ef948d0f7b013a843fdc06",
          "grade": false,
          "grade_id": "cell-4b07a4a33df81dbc",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "outputId": "1af3a7a0-3b84-48a8-ac82-266af77c86e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 79.71%\n"
          ]
        }
      ],
      "source": [
        "test_acc = evaluate(sentiment_lr_model, test_dataloader, device =\"cuda\")\n",
        "print(f\"Test Accuracy: {np.round((100* test_acc),2)}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "N1nsCdSUFrSk",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "29f81cd2d336901422021ec589553a00",
          "grade": false,
          "grade_id": "cell-fb25a045569c78ec",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "We obtain around 80% accuracy form our logistic regression, which is very reasonable considering random guessing will fetch you an accuracy of ~50%. So we are doing ~30% better than random guessing which is good enough for our first model. In the coming lectures we shall see how we can improve this performance even further."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "ejn3fsID1WBf",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "fcc31a2a84b42b33e5d0b6251211f49e",
          "grade": false,
          "grade_id": "cell-62e6eb8240a1076e",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "### Task 3.5: Making Predictions from scratch (0.5 Marks)\n",
        "\n",
        "Now that we have trained the model and evaluated it's performance it seems like a nice place to end, right? However, one aspect that is often overlooked in ML or NLP pipelines is designing an interface that can make prediction directly on a piece of text using the trained model, abstracting away all the pre-processing and model run details from the user. Let's implement the `predict_document` function below that does exactly that\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "deletable": false,
        "id": "Ie6ha5Fw4u5_",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "b4e9e7ac17f2892113f550c8605b11e8",
          "grade": false,
          "grade_id": "cell-c2f8054e4e000f1f",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "def predict_document(document, model, train_vocab, train_word2idx, threshold = 0.5, device = \"cpu\"):\n",
        "  \"\"\"\n",
        "  Predicts the sentiment label for the `document` using `model`\n",
        "\n",
        "  Inputs:\n",
        "    - document (str): The document whose sentiment is to be predicted\n",
        "    - model (LogisticRegressionModel): A trained logistic regression model\n",
        "    - train_vocab (list): Vocabulary on which the model was trained on\n",
        "    - train_word2idx (dict): A Python dictionary mapping each word to its index in vocabulary\n",
        "\n",
        "  Returns:\n",
        "    - pred_label (float): Predicted sentiment of the document\n",
        "\n",
        "  Hint: Follow the following steps:\n",
        "    - preprocess the document\n",
        "    - obtain bag of words features from the preprocessed document\n",
        "    - convert the features to a pytorch tensor using torch.FloatTensor(features)\n",
        "    - feed the features tensor to the model to obtain predicted probabilities\n",
        "    - convert predicted probabilities to labels by checking if predicted probability is greater than or less than the threshold\n",
        "  \"\"\"\n",
        "  \n",
        "  model = model.to(device)\n",
        "  model = model.eval()\n",
        "  pred_label = 1 if sentiment_lr_model(torch.FloatTensor(get_document_bow_feature(document, train_vocab, train_word2idx)).to(device)).tolist()>0.5 else 0\n",
        "  \n",
        "  \n",
        "\n",
        "  return pred_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "uAaBRqkS79eK",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "10108d01159cb6bdfe5627bb387fee6b",
          "grade": true,
          "grade_id": "cell-5366dee98016a849",
          "locked": true,
          "points": 0.5,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "083fa606-1bf4-41af-abc3-791addafe250"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Sample Test Cases\n",
            "Sample Test Case 1\n",
            "Predicted Label: 1\n",
            "Expected Label: 1\n",
            "**********************************\n",
            "\n",
            "Sample Test Case 2\n",
            "Predicted Label: 1\n",
            "Expected Label: 1\n",
            "**********************************\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"Running Sample Test Cases\")\n",
        "\n",
        "print(\"Sample Test Case 1\")\n",
        "sample_document = \"this movie was great\"\n",
        "predicted_label = predict_document(sample_document, sentiment_lr_model,\n",
        "                                   train_vocab, train_word2idx)\n",
        "expected_label = 1\n",
        "print(f\"Predicted Label: {predicted_label}\")\n",
        "print(f\"Expected Label: {expected_label}\")\n",
        "\n",
        "assert predicted_label == expected_label\n",
        "\n",
        "print(\"**********************************\\n\")\n",
        "\n",
        "print(\"Sample Test Case 2\")\n",
        "sample_document = \"This movie was GREAT!!!!\"\n",
        "predicted_label = predict_document(sample_document, sentiment_lr_model,\n",
        "                                   train_vocab, train_word2idx)\n",
        "expected_label = 1\n",
        "print(f\"Predicted Label: {predicted_label}\")\n",
        "print(f\"Expected Label: {expected_label}\")\n",
        "\n",
        "assert predicted_label == expected_label\n",
        "\n",
        "print(\"**********************************\\n\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "8BcJ0z6l-HC-",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "16e9f9504f3302e174e03392fbb3559d",
          "grade": false,
          "grade_id": "cell-5d4627dfa383c43d",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "## Appendix: Interpreting the trained model\n",
        "\n",
        "One of the biggest advantages of using linear models like Logistic Regression is that they are much easier to interpret compared to more sophisticated neural network models. We can just look at the weights of a trained logistic regression model and based on that can determine certain interesting insights about the model. Recall that each weight in a logistic regression corresponds to a feature in the input, and for bag of words each of the feature can be interpreted as a word from the vocabulary. Hence, a large positive weight might indicate that the corresponding word increases the probability of the document containing the positive sentiment, or an overly large negative weight will indicate otherwise. Using this, let's determine the top 10 most positive as well as most negative words. We have implemented the function `get_top_pos_nd_neg_words` to obtain these."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "VMQbujfN-GCW",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "c75b0ea47687be3e2630ffe2502c14f1",
          "grade": false,
          "grade_id": "cell-0c6f890d0aaf5059",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "def get_top_pos_nd_neg_words(model, train_vocab, topk = 10):\n",
        "  \"\"\"\n",
        "  Gets the `topk` most positive and negative words by interpreting the model's weights\n",
        "\n",
        "  Inputs:\n",
        "    - model (LogisticRegressionModel): A trained logistic regression model\n",
        "    - train_vocab (list): Vocabulary on which the model was trained on\n",
        "  \"\"\"\n",
        "\n",
        "  # Obtain model's weights\n",
        "  weights = model.linear_layer.weight.data.detach().cpu().numpy().squeeze()\n",
        "\n",
        "  # Obtain the indices corresponding to most positive and most negative weights\n",
        "  weight_idx = np.argsort(weights)\n",
        "  topk_pos_idxs = weight_idx[-topk:][::-1]\n",
        "  topk_neg_idxs = weight_idx[:topk]\n",
        "\n",
        "  # Get the words from indices\n",
        "  topk_pos_words = [train_vocab[idx] for idx in topk_pos_idxs]\n",
        "  topk_neg_words = [train_vocab[idx] for idx in topk_neg_idxs]\n",
        "\n",
        "  topk_pos_weights = [weights[idx] for idx in topk_pos_idxs]\n",
        "  topk_neg_weights = [weights[idx] for idx in topk_neg_idxs]\n",
        "\n",
        "\n",
        "  return topk_pos_words,topk_pos_weights, topk_neg_words,topk_neg_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "MqV-djM9ArEO",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "98bf2dd41e0ad3168534613d2a748fa2",
          "grade": false,
          "grade_id": "cell-93090c69506164d3",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "8b70fabf-12c7-4976-e9e4-3f9a1cc90a5f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "topk_pos_words,topk_pos_weights, topk_neg_words,topk_neg_weights = get_top_pos_nd_neg_words(sentiment_lr_model, train_vocab, topk = 10)\n",
        "\n",
        "fig = plt.figure(figsize = (15, 5))\n",
        "sns.set(font_scale=1.2)\n",
        "sns.barplot(y = topk_pos_weights + topk_neg_weights,\n",
        "            x = topk_pos_words +topk_neg_words)\n",
        "plt.xticks(rotation=90)\n",
        "plt.ylabel(\"Model Weights\")\n",
        "plt.title(\"Top 10 Most Positive and Top 10 Most Negative Words According to the Model\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "RtDcBINFCnng",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "778694a465631318d1eb9d5a9edcdff3",
          "grade": false,
          "grade_id": "cell-6664531e7e139a3d",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "As you can see the model assigns high weights to words like `terrific`, `refreshing`, `thoughtprovoking` etc, while assigns highly negative values to words like `worst`, `devoid`, `failur`"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Assignment1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}