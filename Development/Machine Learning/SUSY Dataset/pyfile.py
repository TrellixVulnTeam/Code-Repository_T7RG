# -*- coding: utf-8 -*-
"""PYFILE.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OpuF8pwinq0oOBt-MxhyHdOJiWiS_Wrp

## Mounting the drive and navigating to the folder
"""

# mouting the google drive
from google.colab import drive
drive.mount("/gdrive")

# Commented out IPython magic to ensure Python compatibility.
# Navigating to the folder in google drive where the data is stored
# %cd '/gdrive/MyDrive/Colab Notebooks/Project'

"""### Loading all the libraries"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from scipy.stats import zscore
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
import time
import pandas as pd
from sklearn.model_selection import KFold
from sklearn.model_selection import RandomizedSearchCV
from sklearn.naive_bayes import GaussianNB
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import BaggingClassifier
from sklearn.neural_network import MLPClassifier

"""### Reading the file"""

train_data=pd.read_csv('train.csv')

train_data.head(3)

"""### Splitting the data to inputs and outputs

* It can be seen that the first column of the dataset is the index. Since this does not contain any essential information we can drop this column. 

* The last column in the dataset is the output class. This has to be seperated from the other parameters for testing and training purposes.

# Reading the names of columns in the dataset
train_data.columns
"""

x_train=train_data.drop([train_data.columns[0],'class'],axis=1)
y_train=train_data['class']

"""# Dropping the firsy column which is the index and the last column which is the output
# Output is then moved to a different variable called y_train whereas the input is stored in x_train
x_train=train_data.drop([train_data.columns[0],'class'],axis=1)
y_train=train_data['class']

## Exploratory data analysis

x_train.head()

### Finding missing or invalid entries in the dataset

x_train.isna().sum() # Checking if there are missing values in the dataset

It can be seen that there is no missing data in the dataset. Hence , there is no process needed to handle null values. However, we might still have missing values or wrong data

x_train.dtypes # Checking the datatype of all columns in the dataset

<h3> Findings from dtypes </h3>

*  All the datatypes are float64 except the Unnamed 0, which means that there is no data entered as NAN, or as other string formats.

## Understanding the statistical distribution of data

np.round(x_train.describe(),2)

<h3> Findings from describe table </h3>
<body>


*  From the above table, it can be understood that the Unnamed : 0 is the index
* lepton_1_pt is left is right skewed as the mean and standard deviation and inclined towards the lower value of the range of values
* missing_energy_magnitude,MET_rel,M_R,R,S_R,M_delta_R,dphi_r_b
 also has a right skewness

*  The last column is the output column and it has to be seperated. 
*  To understand the dependency of other columns we will have to try other process

### Checking for duplicate values

x_train.duplicated().sum() # Checking if there are any duplicate entries in the dataset

There are no duplicate entries in the database

### Identifying the correlation of data

# Set a threshold to identify pairs more than that
correlation=x_train.corr().T

# Identifying columns with high correlation

high_correlation_list=[]
threshold=0.7
# Iterating through the rows and columns of the correlation matrix to check if there are any columns or parameters that are highly correlated

for x_iter  in correlation.columns:
  for y_iter in correlation.index:
    if x_iter!=y_iter:
      if (correlation[x_iter][y_iter]>threshold) & (correlation[x_iter][y_iter]>(threshold*-1)):
        high_correlation_list.append((x_iter,y_iter,correlation[x_iter][y_iter]))

for element in high_correlation_list:
    print(element)

sns.heatmap(correlation,annot=True)

### Checking for skewness of the data

# It was visible from the datat distribution that certain parameters were skewed to the right. 
# Using the nibuily skew function to check if the parameters are skewed or not

for column in x_train.columns:
  if (train_data[column].skew()>1) | (train_data[column].skew()<-1):
    print(column,'  ',train_data[column].skew())
print( ' The above attributes are skewed ')

### Next steps

* Although it high correaltion and skewness are seen in the above exploration, we have'nt dropeed them as we would like to see the performance of the models with and without these corrections made.

### Dividing the dataset into train and test.

* A random state of 7 is used which will be followed throughout in this process
"""

x_train,x_test,y_train,y_test=train_test_split(x_train,y_train,test_size=0.25,random_state=7)

"""### Creating a subset of the dataset to understand which models perform better and which doesn't"""

x_train_subset,x_test_subset,y_train_subset,y_test_subset=train_test_split(x_train,y_train,test_size=0.40,random_state=7)

"""### Trying different models to see its performance
Here we have tried using
* Logistic Regression
* Decision Tree classifier
* Random Forests of Logistic Regressions
* Random Forests of Decision Tree Classifiers
* Multi Layered Perceptron using sklearn
* Multi Layered Perceptron using tensorflow

x_train_subset.shape

#Creating lists to store results
# This is later used to create a dataframe to summarise all the models created
model_name=[]
score=[]
run_time=[]

##### Logistic regression and Hyper parameter Tuning

start=time.time()
lgR=LogisticRegression(random_state=7)
lgR.fit(x_train_subset,y_train_subset)
t=time.time()-start
model_name.append('Logistic Regression')
score.append(lgR.score(x_test_subset,y_test_subset))
run_time.append(t)

#### Decision tree classifier

start=time.time()
dtClassifier=DecisionTreeClassifier(random_state=7)
dtClassifier.fit(x_train_subset,y_train_subset)
t=time.time()-start
model_name.append('Decision Tree')
score.append(dtClassifier.score(x_test_subset,y_test_subset))
run_time.append(t)

#### Random Forest of Linear Regressions

start=time.time()
lr_random_forest=BaggingClassifier(base_estimator=lgR,n_estimators=10,random_state=17)
lr_random_forest.fit(x_train_subset,y_train_subset)
t=time.time()-start
model_name.append('Random Forest of Logistic Regressions')
score.append(lr_random_forest.score(x_test_subset,y_test_subset))
run_time.append(t)

#### Random Forest of Decision Trees

start=time.time()
lr_random_forest=BaggingClassifier(base_estimator=dtClassifier,n_estimators=10,random_state=17)
lr_random_forest.fit(x_train_subset,y_train_subset)
t=time.time()-start
model_name.append('Random Forest of Decsion Tree Classifiers')
score.append(lr_random_forest.score(x_test_subset,y_test_subset))
run_time.append(t)

### Multi Layered Perceptron

model_name

start=time.time()
mlp=MLPClassifier(random_state=7,max_iter=100,solver='sgd')
mlp.fit(x_train_subset,y_train_subset)
t=time.time()-start
model_name.append('Multi Layered Perceptron')
score.append(mlp.score(x_test_subset,y_test_subset))
run_time.append(t)

results=pd.DataFrame()
results['Model']=model_name
results['Score']=score
results['Train time']=run_time
results

## Findings

* Out of all the models tried, Multi Layered Perceptron seems to be having the best prediction. 
Hence we will be using the same model for further fine tuning and hypter parameter adjustments.

* It can also be seen that the MLP takes lower time than a random forest of decision trees and gives the best accuracy on the training subset data

# Using tensorflow

# Creating a keras model

import tensorflow as tf
import keras
from keras import Sequential,layers



model = keras.Sequential([
    layers.Dense(19, activation='sigmoid', input_shape=(x_train.shape[1],)),
    layers.Dense(100,activation='sigmoid'),
    layers.Dense(50, activation='sigmoid'),
    layers.Dense(25, activation='sigmoid'),
    layers.Dense(10, activation='sigmoid'),
    layers.Dense(1, activation='sigmoid'),
])

model.compile(optimizer='adam',loss='logistic',metrics=['Accuracy'])

dlModel = model.fit(
    x_train, y_train,
    validation_data=(x_test, y_test),
    batch_size=100,
    epochs=50,
    verbose=1
)

df=pd.read_csv('test.csv')
out=pd.DataFrame()
out['Id']=df[df.columns[0]]
df.drop([df.columns[0]],axis=1,inplace=True)
prediction=model.predict(df)
output=[]
for pred in prediction:
  if pred<=0.80:
    output.append(float(0))
  else:
    output.append(float(1))

out['class']=output
out.to_csv('tensorflow81.csv',index=False)

Although the model was able to get good accuracy, the performance of the model on the test dataset in kaggle was pretty low.Hence excluding this model from the final submission

#Creating a multi layered perceptron

### Creating a Multi Layered Perceptron for testing the model

* Training the model with more data
"""

x_train_subset.shape

"""#### Since the MLP took 443 seconds to train on a dataset of size 1.5Million, taking a further subset of the dataset using stratified sampling to find the best hyper parameters. """

#Creating a smaller subset of data
x_train_micro,x_test_micro,y_train_micro,y_test_micro=train_test_split(x_train_subset,y_train_subset,test_size=0.8,stratify=y_train_subset)

x_train_micro.shape

"""## Using Gridsearch cv for hyper parameter tuning of the MLP model

hidden_layer_sizes=[10,12,15,18,20]
solver=['sgd','adam']
activation=['identify','logistic','relu','tanh']
batch_size=[100,300,600,1000]
learning_rate=['constant','invscaling','adaptive']

grid={'hidden_layer_sizes':hidden_layer_sizes,
      'solver':solver,
      'activation':activation,
      'batch_size':batch_size,
      'learning_rate':learning_rate}

random_search=RandomizedSearchCV(estimator=mlp,param_distributions=grid,
                                 n_iter=30,random_state=7,n_jobs=-1,verbose=1)

mlp_search=random_search.fit(x_train_micro,y_train_micro)

mlp_search.best_params_

# Creating a model with the best params as specified by grid search

model=MLPClassifier(hidden_layer_sizes=18,random_state=7,max_iter=100,solver='sgd',batch_size=100)

model.fit(x_train_micro,y_train_micro)

model.score(x_test_micro,y_test_micro)

## Tweaking he hyper parameters more, as the Gridsearch CV Results was not performing well on the test data

model_full_data_tuned=MLPClassifier(hidden_layer_sizes=18,random_state=7,max_iter=100,solver='sgd')
model_full_data_tuned.fit(x_train,y_train)
model_full_data_tuned.score(x_test,y_test)

model_full_data_tuned1=MLPClassifier(hidden_layer_sizes=15,random_state=7,max_iter=200,solver='sgd')
model_full_data_tuned1.fit(x_train,y_train)
model_full_data_tuned1.score(x_test,y_test)

model_full_data_tuned2=MLPClassifier(hidden_layer_sizes=18,random_state=7,max_iter=100,solver='sgd',activation='tanh')
model_full_data_tuned2.fit(x_train,y_train)
model_full_data_tuned2.score(x_test,y_test)

model_full_data_tuned3=MLPClassifier(hidden_layer_sizes=18,random_state=7,max_iter=100,solver='sgd',activation='tanh',learning_rate='constant')
model_full_data_tuned3.fit(x_train,y_train)
model_full_data_tuned3.score(x_test,y_test)

model_full_data4=MLPClassifier(random_state=7,max_iter=100,solver='sgd')
model_full_data4.fit(x_train,y_train)
model_full_data4.score(x_test,y_test)

model_full_data5=MLPClassifier(random_state=7,max_iter=50,solver='sgd')
model_full_data5.fit(x_train,y_train)
model_full_data5.score(x_test,y_test)

model_full_data6=MLPClassifier(random_state=7,max_iter=100,solver='sgd')
model_full_data6.fit(x_train,y_train)
model_full_data6.score(x_test,y_test)

model_full_data_7=MLPClassifier(random_state=7,max_iter=100,solver='adam')
model_full_data_7.fit(x_train,y_train)
model_full_data_7.score(x_test,y_test)

model_full_data_8=MLPClassifier(random_state=7,max_iter=100,solver='adam',activation='logistic')
model_full_data_8.fit(x_train,y_train)
model_full_data_8.score(x_test,y_test)

model_full_data_9=MLPClassifier(random_state=7,max_iter=100,solver='adam',activation='logistic',learning_rate='adaptive')
model_full_data_9.fit(x_train,y_train)
model_full_data_9.score(x_test,y_test)
"""

# Normalising the data and applying the above model again

x_train=train_data.drop([train_data.columns[0],'class'],axis=1)
y_train=train_data['class']
x_train=x_train.apply(zscore)
x_train,x_test,y_train,y_test=train_test_split(x_train,y_train,test_size=0.25,random_state=7)

model_full_data_10=MLPClassifier(random_state=7,max_iter=100,solver='adam',activation='logistic')
model_full_data_10.fit(x_train,y_train)
model_full_data_10.score(x_test,y_test)

"""# Submission using the result obtained in las titeration where the accuracy was the maximum so far.

## submission1(1).csv

df=pd.read_csv('test.csv')
out=pd.DataFrame()
out['Id']=df[df.columns[0]]
df.drop([df.columns[0]],axis=1,inplace=True)
prediction=model_full_data6.predict(df)
out['class']=prediction

out.to_csv('submission1.csv',index=False)

## Submission2.csv

df=pd.read_csv('test.csv')
out=pd.DataFrame()
out['Id']=df[df.columns[0]]
df.drop([df.columns[0]],axis=1,inplace=True)
prediction=model_full_data_7.predict(df)
out['class']=prediction
out.to_csv('submission2.csv',index=False)

```
# This is formatted as code
```

## Submission3.csv

df=pd.read_csv('test.csv')
out=pd.DataFrame()
out['Id']=df[df.columns[0]]
df.drop([df.columns[0]],axis=1,inplace=True)
prediction=model_full_data_8.predict(df)
out['class']=prediction
out.to_csv('submission3.csv',index=False)

## Submission4.csv
"""

df=pd.read_csv('test.csv')
out=pd.DataFrame()
out['Id']=df[df.columns[0]]
df.drop([df.columns[0]],axis=1,inplace=True)
prediction=model_full_data_10.predict(df)
out['class']=prediction
out.to_csv('submission4.csv',index=False)