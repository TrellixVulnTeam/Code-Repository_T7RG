{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyQt5 import QtCore, QtGui, QtWidgets\n",
    "import cv2\n",
    "import os\n",
    "import time\n",
    "import tkinter as tk\n",
    "import tkinter.font as tkFont\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime \n",
    "import datetime as dt\n",
    "\n",
    "\n",
    "total_count=0\n",
    "value=0\n",
    "params=cv2.SimpleBlobDetector_Params() \n",
    "params.filterByArea=True\n",
    "params.maxArea=700\n",
    "params.minArea=120\n",
    "\n",
    "\n",
    "params.filterByCircularity = True\n",
    "params.minCircularity = 0.76\n",
    "\n",
    "\n",
    "brightnessThreshold=0.99\n",
    "detector=cv2.SimpleBlobDetector_create(params)\n",
    "message=''\n",
    "flag=0\n",
    "partCode=''\n",
    "\n",
    "stopExecution=0\n",
    "stopCapture=0\n",
    "stopSet=0\n",
    "recordStatus=0\n",
    "recordFlag=True\n",
    "\n",
    "\n",
    "def ask_tracker():\n",
    "    #print('Enter 0 for Boosting')\n",
    "    #print('Enter 1 for MIL')\n",
    "    #print('Enter 2 for KCF')\n",
    "    #print('Enter 3 for TLD')\n",
    "    #print('Enter 4 for Median Flow')\n",
    "    #choice=input('Enter choice')\n",
    "    choice='6'\n",
    "    if choice=='0':\n",
    "        tracker=cv2.TrackerBoosting_create()\n",
    "    if choice=='1':\n",
    "        tracker=cv2.TrackerMIL_create()\n",
    "    if choice=='2':\n",
    "        tracker=cv2.TrackerKCF_create()\n",
    "    if choice=='3':\n",
    "        tracker=cv2.TrackerTLD_create()\n",
    "    if choice=='4':\n",
    "        tracker=cv2.TrackerMedianFlow_create()\n",
    "    if choice=='5':\n",
    "        tracker=cv2.TrackerCSRT_create()\n",
    "    if choice=='6':\n",
    "        tracker=cv2.TrackerKCF_create()\n",
    "    return tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter  0  for  16acesealnightreduced.mp4\n",
      "Enter  1  for  16facesealreduced.mp4\n",
      "Enter  2  for  3solderreduced.mp4\n",
      "Enter  3  for  5inchcureduced.mp4\n",
      "Enter  4  for  8inchcureduced.mp4\n",
      "Enter  5  for  8inchflarereduced.mp4\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "videoFiles=[]\n",
    "os.chdir('reduced')\n",
    "for filename in os.listdir():\n",
    "    if filename.find('.mp4')>0:\n",
    "        videoFiles.append(filename)\n",
    "        \n",
    "\n",
    "#Code t select the video File\n",
    "i=0\n",
    "for file in videoFiles:\n",
    "    print('Enter ',i,' for ',file)\n",
    "    i+=1\n",
    "choice=input()\n",
    "\n",
    "selectedFile=videoFiles[int(choice)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def furnace():\n",
    "    detector=cv2.SimpleBlobDetector_create(params)\n",
    "    cap=cv2.VideoCapture(selectedFile)\n",
    "    count=0\n",
    "    m_tracker=cv2.MultiTracker_create()\n",
    "    global total_count\n",
    "            \n",
    "    total_count=0\n",
    "    while True:\n",
    "            ## Reading the video frame by frame\n",
    "        try:\n",
    "            ret,frame=cap.read()\n",
    "            x1=0\n",
    "            x2=420\n",
    "            y1=frame.shape[1]\n",
    "            y2=420\n",
    "            display=frame.copy()\n",
    "            (trackerRet,trackerBoxes)=m_tracker.update(frame)\n",
    "\n",
    "            for box in trackerBoxes:\n",
    "                (x, y, w, h) = [int(v) for v in box]\n",
    "                cv2.rectangle(frame, (x-10, y-10), (x + w, y + h), (0, 0, 255), -1)\n",
    "\n",
    "                if len(trackerBoxes)>2:\n",
    "                    count+=len(trackerBoxes)\n",
    "                    m_tracker.clear()\n",
    "    #                 print('Reset Tracker')\n",
    "            #Preprocessing the frame for detection\n",
    "\n",
    "            gray=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "            kernel=np.ones((2,2),np.uint8)\n",
    "            gray=cv2.morphologyEx(gray,cv2.MORPH_CLOSE,kernel)\n",
    "\n",
    "            keypoints=detector.detect(gray)\n",
    "\n",
    "            for i in range(len(keypoints)):\n",
    "                roi=[keypoints[i].pt[0]-10,keypoints[i].pt[1]-10,30,30]\n",
    "                cv2.rectangle(display,(int(roi[0])-10,int(roi[1])-10),(int(roi[0])+30,int(roi[1])+30),(255,0,0),-1)\n",
    "\n",
    "                if (roi[1]>418) & (roi[1]<420):\n",
    "                    m_tracker.add(ask_tracker(),frame,tuple(roi))\n",
    "                    total_count+=1\n",
    "                else:\n",
    "                    pass\n",
    "    #                 cv2.rectangle(frame,(int(roi[0])-10,int(roi[1])-10),(int(roi[0])+30,int(roi[1])+30),(255,0,0),-1)\n",
    "\n",
    "\n",
    "\n",
    "                cv2.putText(display,str(count+len(trackerBoxes)),(50,50),cv2.FONT_HERSHEY_SIMPLEX,1,(0,255,0),3,cv2.LINE_8)\n",
    "                cv2.putText(display,str(total_count),(90,90),cv2.FONT_HERSHEY_SIMPLEX,1,(0,255,0),3,cv2.LINE_8)\n",
    "\n",
    "            cv2.line(display,(x1,x2),(y1,y2),(255,255,0),2)\n",
    "            cv2.imshow('Output',display)\n",
    "\n",
    "            if cv2.waitKey(1) & 0xff==ord('q'):\n",
    "                break\n",
    "        except:\n",
    "            break\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'cv2.cv2' has no attribute 'MultiTracker_create'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-3b1f077924aa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfurnace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-6-50fc77eba19b>\u001b[0m in \u001b[0;36mfurnace\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mcap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVideoCapture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mselectedFile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mcount\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mm_tracker\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMultiTracker_create\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[1;32mglobal\u001b[0m \u001b[0mtotal_count\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'cv2.cv2' has no attribute 'MultiTracker_create'"
     ]
    }
   ],
   "source": [
    "furnace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-51-a206a48bc4aa>, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-51-a206a48bc4aa>\"\u001b[0;36m, line \u001b[0;32m8\u001b[0m\n\u001b[0;31m    for box in boxes:\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "    for i in range(len(keypoints)):\n",
    "        #print(keypoints[i].pt[0],keypoints[i].pt[1])\n",
    "        avg_size.append(keypoints[i].size)\n",
    "        roi=(keypoints[i].pt[0]-10,keypoints[i].pt[1]-10,30,30)\n",
    "        m_tracker.add(self.ask_tracker(),frame,roi)\n",
    "        \n",
    "        \n",
    "            for box in boxes:\n",
    "                (x, y, w, h) = [int(v) for v in box]\n",
    "                if (y+h<x2) & (y+h>80) :\n",
    "\n",
    "                    cv2.rectangle(frame, (x, y), (x + 20, y + 20), (0, 255, 0), 2)\n",
    "                    #frame=cv2.putText(frame,str(y+h),(x,y-10),cv2.FONT_HERSHEY_SIMPLEX,1,(0,255,0),1,cv2.LINE_8)\n",
    "                else:\n",
    "                    obj_count+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'img' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-3b1f077924aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfurnace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-bcbebef6df84>\u001b[0m in \u001b[0;36mfurnace\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Output'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'img' is not defined"
     ]
    }
   ],
   "source": [
    "furnace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def realtime_capture(self):\n",
    "\n",
    "\n",
    "\n",
    "    detector=cv2.SimpleBlobDetector_create(params)\n",
    "\n",
    "\n",
    "\n",
    "    ################################################Reading first frame of video ##########################################\n",
    "    #cap=cv2.VideoCapture(0)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "    #cap=cv2.VideoCapture('furn1.mp4')\n",
    "    cap.set(cv2.CAP_PROP_FPS,120)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ###################################################################################\n",
    "                                  #TEST DETECTION#\n",
    "    ##################################################################################                            \n",
    "    #Reading first frame\n",
    "    ret,frame=cap.read()\n",
    "    frame=cv2.rotate(frame,cv2.ROTATE_180)\n",
    "    hsv=cv2.cvtColor(frame,cv2.COLOR_BGR2HSV)\n",
    "    brightness=hsv[2].mean()\n",
    "    print('Old',brightness)\n",
    "    if brightness< 90:\n",
    "        frame=cv2.addWeighted(frame,brightnessThreshold, np.zeros(frame.shape, frame.dtype), -1, 0.5)\n",
    "\n",
    "    hsv=cv2.cvtColor(frame,cv2.COLOR_BGR2HSV)\n",
    "    brightness=hsv[2].mean()\n",
    "    print('New',brightness)\n",
    "    #Detecting Blobs\n",
    "\n",
    "\n",
    "    frame=cv2.addWeighted(frame,brightnessThreshold, np.zeros(frame.shape, frame.dtype), -1, 0.5)\n",
    "\n",
    "   # frame=cv2.resize(frame,(1024,768))\n",
    "\n",
    "    gray=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "#    kernel=np.ones((2,2),np.uint8)\n",
    "#    gray=cv2.morphologyEx(gray,cv2.MORPH_CLOSE,kernel)\n",
    "    keypoints=detector.detect(gray)\n",
    "\n",
    "    img=cv2.drawKeypoints(frame,keypoints,np.array([]),(0,255,0),cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "    #cv2.imshow('Gray',gray)\n",
    "    #cv2.imshow('Start Frame',img)       \n",
    "    #imt=cv2.putText(frame,str(len(keypoints)),(200,627),cv2.FONT_HERSHEY_SIMPLEX,5,(0,0,255),5,cv2.LINE_8)\n",
    "    #img=cv2.drawKeypoints(imt,keypoints,np.array([]),(0,255,0),cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "    # Create Multitracker\n",
    "\n",
    "    m_tracker=cv2.MultiTracker_create()\n",
    "\n",
    "    #Adding trackers to Multitracker\n",
    "    avg_size=[]\n",
    "    for i in range(len(keypoints)):\n",
    "        #print(keypoints[i].pt[0],keypoints[i].pt[1])\n",
    "        avg_size.append(keypoints[i].size)\n",
    "        roi=(keypoints[i].pt[0]-10,keypoints[i].pt[1]-10,30,30)\n",
    "        m_tracker.add(self.ask_tracker(),frame,roi)\n",
    "    avg_size=np.asarray(avg_size)\n",
    "#    print(avg_size.mean())\n",
    "    #if avg_size.mean()<20:\n",
    "    #    brightnessThreshold=1.5\n",
    "    #    params.maxArea=1000\n",
    "    #    params.minArea=41\n",
    "    #elif avg_size.mean()<15:\n",
    "    #    brightnessThreshold=2\n",
    "    #    params.maxArea=1000\n",
    "    #    params.minArea=41\n",
    "    #elif avg_size.mean()>20:\n",
    "    #    brightnessThreshold=1.7\n",
    "    #    params.filterByCircularity=True\n",
    "    #    params.minCircularity = 0.85\n",
    "    #    params.maxArea=3000\n",
    "    #    params.minArea=120\n",
    "    #    print('8 Inch')\n",
    "    ###################################################################################\n",
    "                                  #REAL DETECTION#\n",
    "    ################################################################################## \n",
    "    ret,frame=cap.read()\n",
    "    #frame=cv2.rotate(frame,cv2.ROTATE_180)\n",
    "\n",
    "    #Detecting Blobs\n",
    "\n",
    "\n",
    "    #frame=cv2.addWeighted(frame,brightnessThreshold, np.zeros(frame.shape, frame.dtype), -1, 0.5)\n",
    "\n",
    "  #  frame=cv2.resize(frame,(1024,768))\n",
    "  #  frame=cv2.rotate(frame,cv2.ROTATE_180)\n",
    "    gray=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "#    kernel=np.ones((2,2),np.uint8)\n",
    "#    gray=cv2.morphologyEx(gray,cv2.MORPH_CLOSE,kernel)\n",
    "    keypoints=detector.detect(gray)\n",
    "\n",
    "    img=cv2.drawKeypoints(frame,keypoints,np.array([]),(0,255,0),cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "\n",
    "    m_tracker=cv2.MultiTracker_create()\n",
    "\n",
    "    #Adding trackers to Multitracker\n",
    "    avg_size=[]\n",
    "    for i in range(len(keypoints)):\n",
    "        #print(keypoints[i].pt[0],keypoints[i].pt[1])\n",
    "        avg_size.append(keypoints[i].size)\n",
    "        roi=(keypoints[i].pt[0]-10,keypoints[i].pt[1]-10,30,30)\n",
    "        m_tracker.add(self.ask_tracker(),frame,roi)\n",
    "\n",
    "\n",
    "    print ('Second detection done')\n",
    "\n",
    "    ###################################################################################\n",
    "                                #DETECTION ON VIDEO#\n",
    "    ################################################################################## \n",
    "\n",
    "\n",
    "\n",
    "    # Tracking the objects on video\n",
    "    total_count=0\n",
    "    count=0\n",
    "    obj_count=0\n",
    "\n",
    "    print (ret)\n",
    "\n",
    "    while ret:\n",
    "        minute=dt.datetime.now().minute\n",
    "        second=dt.datetime.now().second\n",
    "        hour=dt.datetime.now().hour\n",
    "\n",
    "     ###################################################################################\n",
    "                                #SQL Update#\n",
    "    ################################################################################## \n",
    "\n",
    "\n",
    "        if minute==59 and second>55 and flag==0:\n",
    "\n",
    "\n",
    "            query='INSERT INTO [IN_Digitalization].[dbo].[FD_Furnace] ( Input,PartCode,t_stamp) VALUES ('+str(total_count)+\",'\"+str(partCode)+\"',GETDATE())\"\n",
    "            cursor.execute(query)\n",
    "            conn.commit()\n",
    "            flag=1\n",
    "        if minute==0 and flag==1:\n",
    "            flag=0\n",
    "\n",
    "\n",
    "     ###################################################################################\n",
    "                                #Video Detection#\n",
    "    ################################################################################## \n",
    "\n",
    "        ret,frame=cap.read()\n",
    "        frame=cv2.rotate(frame,cv2.ROTATE_180)\n",
    "        if ret:\n",
    "            count+=1\n",
    "            ############3Delete \n",
    "            frame=cv2.addWeighted(frame,brightnessThreshold, np.zeros(frame.shape, frame.dtype), -1, 0.5)\n",
    "         #   frame=cv2.resize(frame,(1024,768))\n",
    "         #   frame=cv2.rotate(frame,cv2.ROTATE_180)\n",
    "            recordFrame=frame.copy()\n",
    "            x1=0\n",
    "            x2=frame.shape[0]-120\n",
    "            y1=frame.shape[1]\n",
    "            y2=frame.shape[0]-120\n",
    "            cv2.line(frame,(x1,x2),(y1,y2),(0,255,0),2)\n",
    "\n",
    "            (retb,boxes)=m_tracker.update(frame)\n",
    "\n",
    "            for box in boxes:\n",
    "                (x, y, w, h) = [int(v) for v in box]\n",
    "                if (y+h<x2) & (y+h>80) :\n",
    "\n",
    "                    cv2.rectangle(frame, (x, y), (x + 20, y + 20), (0, 255, 0), 2)\n",
    "                    #frame=cv2.putText(frame,str(y+h),(x,y-10),cv2.FONT_HERSHEY_SIMPLEX,1,(0,255,0),1,cv2.LINE_8)\n",
    "                else:\n",
    "                    obj_count+=1\n",
    "\n",
    "            #TOTAL IS THE NUMBER OF OBJECTS IN CURRENT FRAME\n",
    "\n",
    "            remaining=len(boxes)-obj_count\n",
    "\n",
    "\n",
    "\n",
    "            if int(remaining)<5:\n",
    "\n",
    "                numberCrossed=0\n",
    "                print(len(boxes))\n",
    "                for box in boxes:\n",
    "                    (x, y, w, h) = [int(v) for v in box]\n",
    "\n",
    "                    if (y+h>x2) & (y+h<80):\n",
    "\n",
    "                        ## Hiding the already detected objects\n",
    "                        frame=cv2.rectangle(frame, (x, y), (x + w+8, y + h+8), (0, 255,0), -1)\n",
    "\n",
    "                    else:\n",
    "                        numberCrossed+=1\n",
    "                frame=cv2.rectangle(frame,(0,frame.shape[0]),(frame.shape[1],frame.shape[1]),(0,255,0),-1) \n",
    "\n",
    "##                       \n",
    "#                    if len(boxes)==0:\n",
    "#                        new_frame=frame\n",
    "\n",
    "                gray=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "                keypoints=detector.detect(gray)\n",
    "\n",
    "\n",
    "                # Create new tracking if more than 5 parts are detected\n",
    "                if len(keypoints)>5:\n",
    "                    #print('inside')\n",
    "                    #m_tracker.release()\n",
    "                    m_tracker=cv2.MultiTracker_create()\n",
    "                    avg_size=[]\n",
    "\n",
    "                    for i in range(len(keypoints)):\n",
    "#                        print('Test',keypoints[i].size)\n",
    "                        #print(keypoints[i].pt[0],keypoints[i].pt[1])\n",
    "                        roi=(keypoints[i].pt[0]-10,keypoints[i].pt[1]-10,30,30)\n",
    "                        avg_size.append(keypoints[i].size)\n",
    "                        m_tracker.add(self.ask_tracker(),frame,roi)\n",
    "                    print(len(keypoints),' Keypoints')  \n",
    "                    avg_size=np.asarray(avg_size)\n",
    "                    print(avg_size.mean())\n",
    "                    #if avg_size.mean()<20:\n",
    "                    #    brightnessThreshold=1.5\n",
    "                    #    params.maxArea=1000\n",
    "                    #    params.minArea=41\n",
    "                    #elif avg_size.mean()<15:\n",
    "                    #    brightnessThreshold=2\n",
    "                    #    params.maxArea=1000\n",
    "                    #    params.minArea=41\n",
    "                    #elif avg_size.mean()>20:\n",
    "                    #    brightnessThreshold=1.7\n",
    "                    #    params.filterByCircularity=True\n",
    "                    #    params.minCircularity = 0.85\n",
    "                    #    params.maxArea=3000\n",
    "                    #    params.minArea=120\n",
    "                    #    print('8 inch')\n",
    "\n",
    "                    total_count=total_count+(len(boxes)-remaining)\n",
    "            obj_count=0\n",
    "            frame=cv2.putText(frame,'In Frame:'+str(remaining),(0,20),cv2.FONT_HERSHEY_SIMPLEX,1,(0,255,0),3,cv2.LINE_8)\n",
    "            #frame=cv2.putText(frame,'Total:'+str(total_count+len(boxes)-remaining),(0,60),cv2.FONT_HERSHEY_SIMPLEX,1,(0,255,0),5,cv2.LINE_8)\n",
    "            #print(total_count,len(boxes),remaining,total_count+len(boxes)-remaining)\n",
    "            self.lcdNumber_2.display(total_count+len(boxes)-remaining)\n",
    "            self.viewCam(frame)\n",
    "\n",
    "\n",
    "            if (recordStatus==1) & recordFlag:\n",
    "                fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "                ext=str(dt.datetime.now().minute)+str(dt.datetime.now().second)\n",
    "                out = cv2.VideoWriter('output'+ext+'.mp4', fourcc, 20.0, (recordFrame.shape[1],recordFrame.shape[0]))\n",
    "                recordFlag=False\n",
    "                print('Initialized')\n",
    "            elif (recordStatus==1) & (not recordFlag):\n",
    "              #  recordFrame=cv2.resize(recordFrame,(1024,768))  \n",
    "                out.write(recordFrame)\n",
    "                print('Recording')\n",
    "            elif (recordStatus==0) & (not recordFlag):\n",
    "                out.release()\n",
    "                recordFlag=True\n",
    "                print('Stopped')\n",
    "\n",
    "            #cv2.imshow('Video',frame)\n",
    "\n",
    "        if cv2.waitKey(1)==ord('q'):\n",
    "            break\n",
    "        if stopExecution==1:\n",
    "            stopExecution=0\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
