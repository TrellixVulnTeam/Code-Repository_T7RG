{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TThE6KcKKUB"
      },
      "source": [
        "<h2> Files</h2>\n",
        "<body>\n",
        "    <b>smiles </b>: Virtual Environment - Use source /smiles/bin/activate to activate the virtual env<br>\n",
        "    <b>datasets/download.sh </b>: Bash script to download datasets \n",
        "\t\tUsage : bash download.sh gdb13 OR bash download.sh gdb17 or bash download.sh gdb17\n",
        "<br>\n",
        "    <b>datasets/delete.sh </b>: bash script to delete files in the folder. \n",
        "\t\tUsage : bash delete.sh gdb11_ where gdb11 is the grep string to search for.\n",
        "<br>\n",
        "    <b>datasets/extract.sh </b>: To extract files from a tar file and to save it in a folder\n",
        "\n",
        "<br>\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions"
      ],
      "metadata": {
        "id": "1xpDCUaKnAk7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparing the data"
      ],
      "metadata": {
        "id": "8eBhDkgUNOx4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Connecting to google drive and navigating to folder\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "os.chdir(\"drive/MyDrive/Colab Notebooks/molecule_generation_SMILES/scripts\")"
      ],
      "metadata": {
        "id": "pskcxzApKbny",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47a428cb-52a3-4339-ec30-8619707b86cc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Kt33dM6UKKUJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0075ad3c-2b68-4ab3-befe-b99a5c91c45a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting smilite\n",
            "  Downloading smilite-2.3.0-py2.py3-none-any.whl (18 kB)\n",
            "Collecting PyPrind>=2.3.1\n",
            "  Downloading PyPrind-2.11.3-py2.py3-none-any.whl (8.4 kB)\n",
            "Installing collected packages: PyPrind, smilite\n",
            "Successfully installed PyPrind-2.11.3 smilite-2.3.0\n"
          ]
        }
      ],
      "source": [
        "!pip install smilite\n",
        "# Importing Libraries\n",
        "import pandas as pd\n",
        "import smilite # Library to check if data generated is correct or not\n",
        "from check_molecule import *\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading the saved Nump file\n",
        "import numpy as np\n",
        "data_en=np.load('smiles_zinc.npz',allow_pickle=True)\n",
        "key_value=data_en['key'].item()\n",
        "data_en=data_en['ohe']"
      ],
      "metadata": {
        "id": "-AvKaL2R6b65"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM Autoencoder\n",
        "Reference : TowardsDataScience post on LSTM AutoEncoders by Chitta Ranjan\n"
      ],
      "metadata": {
        "id": "0oMCXmTNrE4P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "slicing_point=int(len(data_en)*0.75)\n",
        "x_train=data_en[:slicing_point]\n",
        "x_test=data_en[slicing_point:]"
      ],
      "metadata": {
        "id": "cqgJvMhv1KXv"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# The motive here is to create a Deep autoencoder\n",
        "from keras import Sequential\n",
        "from keras.layers import LSTM,Dense,RepeatVector\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(LSTM(32, activation='relu', input_shape=(32,32), return_sequences=True))\n",
        "model.add(LSTM(8, activation='relu', return_sequences=False))\n",
        "model.add(RepeatVector(32))\n",
        "model.add(LSTM(64, activation='relu', return_sequences=True))\n",
        "model.add(LSTM(128, activation='relu', return_sequences=True))\n",
        "model.add(Dense(32, activation='softmax'))\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "model.summary()\n",
        "import time\n",
        "\n",
        "start=time.time()\n",
        "model.fit(x_train,x_train,epochs = 5,\n",
        "          batch_size=512,\n",
        "          shuffle = True,\n",
        "          validation_data = (x_test,x_test))\n",
        "time_taken=time.time()-start\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jN0_tOIjv-Nw",
        "outputId": "c384a867-a98f-46b6-fced-4ed271305721"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 32, 32)            8320      \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 8)                 1312      \n",
            "                                                                 \n",
            " repeat_vector (RepeatVector  (None, 32, 8)            0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 32, 64)            18688     \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 32, 128)           98816     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 32, 32)            4128      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 131,264\n",
            "Trainable params: 131,264\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "124/124 [==============================] - 26s 172ms/step - loss: 0.3156 - val_loss: 0.1026\n",
            "Epoch 2/5\n",
            "124/124 [==============================] - 21s 167ms/step - loss: 0.0959 - val_loss: 0.0928\n",
            "Epoch 3/5\n",
            "124/124 [==============================] - 21s 166ms/step - loss: 0.0903 - val_loss: 0.0883\n",
            "Epoch 4/5\n",
            "124/124 [==============================] - 21s 166ms/step - loss: 0.0871 - val_loss: 0.0850\n",
            "Epoch 5/5\n",
            "124/124 [==============================] - 21s 166ms/step - loss: 0.0845 - val_loss: 0.0838\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Time taken in GPU is ',time_taken )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZZ_CH37ud4_",
        "outputId": "814cd990-6412-4d8a-c12e-5680f59c75be"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time taken in GPU is  109.16162943840027\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# The motive here is to create a Deep autoencoder\n",
        "from keras import Sequential\n",
        "from keras.layers import LSTM,Dense,RepeatVector\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(LSTM(32, activation='relu', input_shape=(32,32), return_sequences=True))\n",
        "model.add(LSTM(8, activation='relu', return_sequences=False))\n",
        "model.add(RepeatVector(32))\n",
        "model.add(LSTM(64, activation='relu', return_sequences=True))\n",
        "model.add(LSTM(128, activation='relu', return_sequences=True))\n",
        "model.add(Dense(32, activation='softmax'))\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "model.summary()\n",
        "import time\n",
        "\n",
        "start=time.time()\n",
        "model.fit(x_train,x_train,epochs = 5,\n",
        "          batch_size=512,\n",
        "          shuffle = True,\n",
        "          validation_data = (x_test,x_test))\n",
        "time_taken=time.time()-start\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JakMZc9Xu4jf",
        "outputId": "ba53d894-53a0-4ab1-aeff-b48df3b8340c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 32, 32)            8320      \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 8)                 1312      \n",
            "                                                                 \n",
            " repeat_vector (RepeatVector  (None, 32, 8)            0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 32, 64)            18688     \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 32, 128)           98816     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 32, 32)            4128      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 131,264\n",
            "Trainable params: 131,264\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "124/124 [==============================] - 73s 550ms/step - loss: 0.2443 - val_loss: 0.0975\n",
            "Epoch 2/5\n",
            "124/124 [==============================] - 68s 545ms/step - loss: 0.0964 - val_loss: 0.0944\n",
            "Epoch 3/5\n",
            "124/124 [==============================] - 68s 550ms/step - loss: 0.0922 - val_loss: 0.0894\n",
            "Epoch 4/5\n",
            "124/124 [==============================] - 67s 542ms/step - loss: 0.0881 - val_loss: 0.0863\n",
            "Epoch 5/5\n",
            "124/124 [==============================] - 68s 549ms/step - loss: 0.0855 - val_loss: 0.0854\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Time taken on the CPU is ',time_taken)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8eTW8qWu5pb",
        "outputId": "ce1f3dfa-b0ee-40e8-a117-c7134463f74d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time taken on the CPU is  386.9927065372467\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "GPU VS CPU molecule_generation using LSTM AutoEncoder.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}